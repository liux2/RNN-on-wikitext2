{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51504a5-8d45-4e56-bfa2-65624e8dd6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prerequisite\n",
    "! pip install pytorch_lightning\n",
    "! pip install nltk\n",
    "!python -m nltk.downloader punkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e222f3a6-73a9-442d-815b-b0547748a008",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import math\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import pytorch_lightning.loggers as pl_loggers\n",
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import random\n",
    "import operator\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f53184ad-91bc-4f83-84b0-b1b1c9dd53d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prep:\n",
    "    \"\"\"Preparing tokenization and frequences.\"\"\"\n",
    "    def __init__(self):\n",
    "        with open(\"./data/wiki.test.txt\") as f:\n",
    "            self.test = f.read()\n",
    "        with open(\"./data/wiki.train.txt\") as f:\n",
    "            self.train = f.read()\n",
    "        with open(\"./data/wiki.valid.txt\") as f:\n",
    "            self.valid = f.read()\n",
    "        # self.test1 = \"After release , it received downloadable content . along with an expanded edition in November of that year .\"\n",
    "        # self.test2 = \"After it received .\"\n",
    "        self.word_freqs = {\"<oov>\":1}\n",
    "\n",
    "    def tokenize(self, corpus):\n",
    "        \"\"\"\n",
    "        Tokenized the lines, remove the titles, and make it lowercase,\n",
    "        return lines list.\n",
    "        list[list[word]]\n",
    "        \"\"\"\n",
    "        \n",
    "        # Create token list\n",
    "        sent_tokens = [word_tokenize(t) for t in sent_tokenize(corpus)]\n",
    "        random.shuffle(sent_tokens)\n",
    "        word_tokens = [[w.lower() for w in s] for s in sent_tokens]\n",
    "        \n",
    "        # Remove last punctuation, add <s></s>\n",
    "        word_tokens = [[\"<s>\"] + s + [\"</s>\"] if s[-1].isalnum() else [\"<s>\"] + s[:-1] + [\"</s>\"] for s in word_tokens]\n",
    "        corpus = []\n",
    "        for s in word_tokens:\n",
    "            corpus.extend(s)\n",
    "        return corpus\n",
    "    \n",
    "    def building_vocab(self, corpus):\n",
    "        \"\"\"Building vocab list from training set.\"\"\"\n",
    "        for w in corpus:\n",
    "            # the word has already been found\n",
    "            if w in self.word_freqs:\n",
    "                self.word_freqs[w] += 1\n",
    "            # the word has not yet already been found\n",
    "            else:\n",
    "                self.word_freqs[w] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c3d95cb-b843-4570-a2ce-e4aaee398cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab(object):\n",
    "    \"\"\" Converts word tokens to indices, and vice versa. \"\"\"\n",
    "\n",
    "    def __init__(self, freqs, corpus, window_size):\n",
    "        super().__init__()\n",
    "        self.indix2token = tuple(freqs)\n",
    "        self.token2index = {k: v for v, k in enumerate(self.indix2token)}\n",
    "        self.corpus = corpus\n",
    "        self.window_size = window_size\n",
    "        self.encoded_list = []\n",
    "        self.data, self.target = self.encoding()\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.encoded_list)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return torch.tensor(self.data[key]),torch.tensor(self.target[key])\n",
    "\n",
    "    def encoding(self):  \n",
    "        def retrive(key):\n",
    "            if isinstance(key, int):\n",
    "                return None\n",
    "            else:\n",
    "                return self.token2index[key]\n",
    "        encoded_list = [retrive(i) for i in self.corpus]\n",
    "        self.encoded_list = [encoded_list[i:i + self.window_size] for i in range(0, len(encoded_list), self.window_size) if len(encoded_list[i:i + self.window_size])==self.window_size]\n",
    "        data = [s[:-1] for s in self.encoded_list]\n",
    "        target = [s[1:] for s in self.encoded_list]\n",
    "        return data, target\n",
    "    \n",
    "    def decoding(self):\n",
    "        def retrive(self, key):\n",
    "            if isinstance(key, int):\n",
    "                return self.indix2token[key]\n",
    "            else:\n",
    "                return None\n",
    "        decoded_list = [[retrive(w) for w in s] for s in self.corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af18a205-5c5b-4803-8b84-a320abaeb4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Prep()\n",
    "# Prepare vocab\n",
    "train_corpus = p.tokenize(p.train)\n",
    "p.building_vocab(train_corpus)\n",
    "\n",
    "valid_corpus = p.tokenize(p.valid)\n",
    "p.building_vocab(valid_corpus)\n",
    "\n",
    "test_corpus = p.tokenize(p.test)\n",
    "p.building_vocab(test_corpus)\n",
    "\n",
    "word_freqs = p.word_freqs\n",
    "\n",
    "train = Vocab(word_freqs, train_corpus, 31)\n",
    "valid = Vocab(word_freqs, valid_corpus, 31)\n",
    "test = Vocab(word_freqs, test_corpus, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18b312ae-8abd-43d5-b684-098352c54eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDateModule(pl.LightningDataModule):\n",
    "    \"\"\"Pytorch lightning data module.\"\"\"\n",
    "    def __init__(self, train_corpus, valid_corpus, test_corpus):\n",
    "        super().__init__()\n",
    "        self.batch_size = 20\n",
    "        self.train = train_corpus\n",
    "        self.valid = valid_corpus\n",
    "        self.test = test_corpus\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.train, self.batch_size, num_workers=16, shuffle=True, drop_last=True)\n",
    "  \n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.valid, self.batch_size, num_workers=16, shuffle=False, drop_last=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.test, self.batch_size, num_workers=16, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f88bfbc3-6949-4d61-8d38-1f9cc8266f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextLightningModule(pl.LightningModule):\n",
    "    \"\"\"RNN module\"\"\"\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.num_layers = 2\n",
    "        self.hidden_size = 100 #200\n",
    "        self.embedding_size = 100\n",
    "        self.vocab_size = vocab_size\n",
    "        \n",
    "        # embedding\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_size)\n",
    "        nn.init.uniform_(self.embedding.weight, -0.1, 0.1)\n",
    "        #layers\n",
    "        self.rnn = nn.RNN(self.embedding_size, self.hidden_size, self.num_layers, batch_first=True)\n",
    "        self.out_fc = nn.Linear(self.hidden_size, vocab_size)\n",
    "        # loss funciton\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        \n",
    "    \n",
    "    def forward(self, data, hidden):\n",
    "        embedding = self.dropout(self.embedding(data))\n",
    "        output, hidden = self.rnn(embedding, hidden)\n",
    "        output = self.out_fc(output)\n",
    "        return output.view(-1, self.vocab_size), hidden\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.SGD(self.parameters(), lr=5e-1)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x,y = batch\n",
    "        y = y.view(-1)\n",
    "        \n",
    "        hidden = torch.zeros(self.num_layers, 20, self.hidden_size).to(self.device)\n",
    "        output, hidden = self.forward(x, hidden)\n",
    "        loss = self.loss(output, y)\n",
    "        perplexity = math.exp(loss.item())\n",
    "        \n",
    "        tensorboard_logs = {'perplexity': {'train': perplexity}, 'loss': {'train': loss.detach()}}\n",
    "        self.log(\"loss/train\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"perplexity/train\", perplexity, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return {\"loss\": loss, \"log\": tensorboard_logs}\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x,y = batch\n",
    "        y = y.view(-1)\n",
    "        \n",
    "        hidden = torch.zeros(self.num_layers, 20, self.hidden_size).to(self.device)\n",
    "        output, hidden = self.forward(x, hidden)\n",
    "        loss = self.loss(output, y)\n",
    "        perplexity = math.exp(loss.item())\n",
    "        \n",
    "        tensorboard_logs = {'perplexity': {'valid': perplexity}, 'loss': {'valid': loss.detach()}}\n",
    "        self.log(\"loss/valid\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"perplexity/valid\", perplexity, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return {\"loss\": loss, \"log\": tensorboard_logs}\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x,y = batch\n",
    "        y = y.view(-1)\n",
    "        \n",
    "        hidden = torch.zeros(self.num_layers, 20, self.hidden_size).to(self.device)\n",
    "        output, hidden = self.forward(x, hidden)\n",
    "        loss = self.loss(output, y)\n",
    "        perplexity = math.exp(loss.item())\n",
    "        \n",
    "        tensorboard_logs = {'perplexity': {'test': perplexity}, 'loss': {'test': loss.detach()}}\n",
    "        self.log(\"loss/test\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"perplexity/test\", perplexity, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return {\"loss\": loss, \"log\": tensorboard_logs}\n",
    "\n",
    "    def init_hidden(self, batch_size = 20):\n",
    "        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11a6a615-a36f-4dbb-8c03-fa0bf4cf1897",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Missing logger folder: ./lightning_logs/network_1\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | embedding | Embedding        | 2.9 M \n",
      "1 | rnn       | RNN              | 40.4 K\n",
      "2 | out_fc    | Linear           | 2.9 M \n",
      "3 | loss      | CrossEntropyLoss | 0     \n",
      "4 | dropout   | Dropout          | 0     \n",
      "-----------------------------------------------\n",
      "5.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.8 M     Total params\n",
      "23.400    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  90%|█████████ | 3687/4091 [00:35<00:03, 104.84it/s, loss=5.8, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                       | 0/404 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  90%|█████████ | 3692/4091 [00:35<00:03, 103.31it/s, loss=5.8, v_num=0]\u001b[A\n",
      "Epoch 0:  91%|█████████ | 3716/4091 [00:35<00:03, 103.69it/s, loss=5.8, v_num=0]\u001b[A\n",
      "Epoch 0:  91%|█████████▏| 3742/4091 [00:35<00:03, 104.12it/s, loss=5.8, v_num=0]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 3768/4091 [00:36<00:03, 104.54it/s, loss=5.8, v_num=0]\u001b[A\n",
      "Epoch 0:  93%|█████████▎| 3794/4091 [00:36<00:02, 104.96it/s, loss=5.8, v_num=0]\u001b[A\n",
      "Epoch 0:  93%|█████████▎| 3820/4091 [00:36<00:02, 105.38it/s, loss=5.8, v_num=0]\u001b[A\n",
      "Epoch 0:  94%|█████████▍| 3846/4091 [00:36<00:02, 105.79it/s, loss=5.8, v_num=0]\u001b[A\n",
      "Epoch 0:  95%|█████████▍| 3872/4091 [00:36<00:02, 106.20it/s, loss=5.8, v_num=0]\u001b[A\n",
      "Epoch 0:  95%|█████████▌| 3898/4091 [00:36<00:01, 106.60it/s, loss=5.8, v_num=0]\u001b[A\n",
      "Epoch 0:  96%|█████████▌| 3924/4091 [00:36<00:01, 107.00it/s, loss=5.8, v_num=0]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 3950/4091 [00:36<00:01, 107.40it/s, loss=5.8, v_num=0]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 3976/4091 [00:36<00:01, 107.81it/s, loss=5.8, v_num=0]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 4002/4091 [00:36<00:00, 108.21it/s, loss=5.8, v_num=0]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 4028/4091 [00:37<00:00, 108.61it/s, loss=5.8, v_num=0]\u001b[A\n",
      "Epoch 0:  99%|█████████▉| 4054/4091 [00:37<00:00, 109.00it/s, loss=5.8, v_num=0]\u001b[A\n",
      "Epoch 0: 100%|█| 4091/4091 [00:37<00:00, 109.32it/s, loss=5.8, v_num=0, loss/val\u001b[A\n",
      "Epoch 1:  90%|▉| 3687/4091 [00:35<00:03, 104.20it/s, loss=5.52, v_num=0, loss/va\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                       | 0/404 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  90%|▉| 3692/4091 [00:35<00:03, 102.67it/s, loss=5.52, v_num=0, loss/va\u001b[A\n",
      "Epoch 1:  91%|▉| 3718/4091 [00:36<00:03, 103.10it/s, loss=5.52, v_num=0, loss/va\u001b[A\n",
      "Epoch 1:  92%|▉| 3744/4091 [00:36<00:03, 103.52it/s, loss=5.52, v_num=0, loss/va\u001b[A\n",
      "Epoch 1:  92%|▉| 3770/4091 [00:36<00:03, 103.94it/s, loss=5.52, v_num=0, loss/va\u001b[A\n",
      "Epoch 1:  93%|▉| 3796/4091 [00:36<00:02, 104.35it/s, loss=5.52, v_num=0, loss/va\u001b[A\n",
      "Epoch 1:  93%|▉| 3822/4091 [00:36<00:02, 104.77it/s, loss=5.52, v_num=0, loss/va\u001b[A\n",
      "Epoch 1:  94%|▉| 3848/4091 [00:36<00:02, 105.18it/s, loss=5.52, v_num=0, loss/va\u001b[A\n",
      "Epoch 1:  95%|▉| 3874/4091 [00:36<00:02, 105.59it/s, loss=5.52, v_num=0, loss/va\u001b[A\n",
      "Epoch 1:  95%|▉| 3900/4091 [00:36<00:01, 106.00it/s, loss=5.52, v_num=0, loss/va\u001b[A\n",
      "Epoch 1:  96%|▉| 3926/4091 [00:36<00:01, 106.40it/s, loss=5.52, v_num=0, loss/va\u001b[A\n",
      "Epoch 1:  97%|▉| 3952/4091 [00:37<00:01, 106.80it/s, loss=5.52, v_num=0, loss/va\u001b[A\n",
      "Epoch 1:  97%|▉| 3978/4091 [00:37<00:01, 107.20it/s, loss=5.52, v_num=0, loss/va\u001b[A\n",
      "Epoch 1:  98%|▉| 4004/4091 [00:37<00:00, 107.59it/s, loss=5.52, v_num=0, loss/va\u001b[A\n",
      "Epoch 1:  99%|▉| 4030/4091 [00:37<00:00, 107.99it/s, loss=5.52, v_num=0, loss/va\u001b[A\n",
      "Epoch 1:  99%|▉| 4056/4091 [00:37<00:00, 108.38it/s, loss=5.52, v_num=0, loss/va\u001b[A\n",
      "Epoch 1: 100%|▉| 4082/4091 [00:37<00:00, 108.78it/s, loss=5.52, v_num=0, loss/va\u001b[A\n",
      "Epoch 1: 100%|█| 4091/4091 [00:37<00:00, 108.64it/s, loss=5.52, v_num=0, loss/va\u001b[A\n",
      "Epoch 2:  90%|▉| 3687/4091 [00:35<00:03, 103.49it/s, loss=5.42, v_num=0, loss/va\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                       | 0/404 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:  90%|▉| 3692/4091 [00:36<00:03, 101.97it/s, loss=5.42, v_num=0, loss/va\u001b[A\n",
      "Epoch 2:  91%|▉| 3718/4091 [00:36<00:03, 102.38it/s, loss=5.42, v_num=0, loss/va\u001b[A\n",
      "Epoch 2:  92%|▉| 3744/4091 [00:36<00:03, 102.80it/s, loss=5.42, v_num=0, loss/va\u001b[A\n",
      "Epoch 2:  92%|▉| 3770/4091 [00:36<00:03, 103.22it/s, loss=5.42, v_num=0, loss/va\u001b[A\n",
      "Epoch 2:  93%|▉| 3796/4091 [00:36<00:02, 103.64it/s, loss=5.42, v_num=0, loss/va\u001b[A\n",
      "Epoch 2:  93%|▉| 3822/4091 [00:36<00:02, 104.05it/s, loss=5.42, v_num=0, loss/va\u001b[A\n",
      "Epoch 2:  94%|▉| 3848/4091 [00:36<00:02, 104.45it/s, loss=5.42, v_num=0, loss/va\u001b[A\n",
      "Epoch 2:  95%|▉| 3874/4091 [00:36<00:02, 104.85it/s, loss=5.42, v_num=0, loss/va\u001b[A\n",
      "Epoch 2:  95%|▉| 3900/4091 [00:37<00:01, 105.26it/s, loss=5.42, v_num=0, loss/va\u001b[A\n",
      "Epoch 2:  96%|▉| 3926/4091 [00:37<00:01, 105.66it/s, loss=5.42, v_num=0, loss/va\u001b[A\n",
      "Epoch 2:  97%|▉| 3952/4091 [00:37<00:01, 106.06it/s, loss=5.42, v_num=0, loss/va\u001b[A\n",
      "Epoch 2:  97%|▉| 3978/4091 [00:37<00:01, 106.46it/s, loss=5.42, v_num=0, loss/va\u001b[A\n",
      "Epoch 2:  98%|▉| 4004/4091 [00:37<00:00, 106.85it/s, loss=5.42, v_num=0, loss/va\u001b[A\n",
      "Epoch 2:  99%|▉| 4030/4091 [00:37<00:00, 107.25it/s, loss=5.42, v_num=0, loss/va\u001b[A\n",
      "Epoch 2:  99%|▉| 4056/4091 [00:37<00:00, 107.64it/s, loss=5.42, v_num=0, loss/va\u001b[A\n",
      "Epoch 2: 100%|▉| 4082/4091 [00:37<00:00, 108.04it/s, loss=5.42, v_num=0, loss/va\u001b[A\n",
      "Epoch 2: 100%|█| 4091/4091 [00:37<00:00, 107.93it/s, loss=5.42, v_num=0, loss/va\u001b[A\n",
      "Epoch 3:  90%|▉| 3687/4091 [00:35<00:03, 103.66it/s, loss=5.26, v_num=0, loss/va\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                       | 0/404 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:  90%|▉| 3692/4091 [00:36<00:03, 102.14it/s, loss=5.26, v_num=0, loss/va\u001b[A\n",
      "Epoch 3:  91%|▉| 3718/4091 [00:36<00:03, 102.57it/s, loss=5.26, v_num=0, loss/va\u001b[A\n",
      "Epoch 3:  92%|▉| 3744/4091 [00:36<00:03, 102.99it/s, loss=5.26, v_num=0, loss/va\u001b[A\n",
      "Epoch 3:  92%|▉| 3770/4091 [00:36<00:03, 103.41it/s, loss=5.26, v_num=0, loss/va\u001b[A\n",
      "Epoch 3:  93%|▉| 3796/4091 [00:36<00:02, 103.83it/s, loss=5.26, v_num=0, loss/va\u001b[A\n",
      "Epoch 3:  93%|▉| 3822/4091 [00:36<00:02, 104.24it/s, loss=5.26, v_num=0, loss/va\u001b[A\n",
      "Epoch 3:  94%|▉| 3848/4091 [00:36<00:02, 104.65it/s, loss=5.26, v_num=0, loss/va\u001b[A\n",
      "Epoch 3:  95%|▉| 3874/4091 [00:36<00:02, 105.05it/s, loss=5.26, v_num=0, loss/va\u001b[A\n",
      "Epoch 3:  95%|▉| 3900/4091 [00:36<00:01, 105.44it/s, loss=5.26, v_num=0, loss/va\u001b[A\n",
      "Epoch 3:  96%|▉| 3926/4091 [00:37<00:01, 105.84it/s, loss=5.26, v_num=0, loss/va\u001b[A\n",
      "Epoch 3:  97%|▉| 3952/4091 [00:37<00:01, 106.24it/s, loss=5.26, v_num=0, loss/va\u001b[A\n",
      "Epoch 3:  97%|▉| 3978/4091 [00:37<00:01, 106.64it/s, loss=5.26, v_num=0, loss/va\u001b[A\n",
      "Epoch 3:  98%|▉| 4004/4091 [00:37<00:00, 107.03it/s, loss=5.26, v_num=0, loss/va\u001b[A\n",
      "Epoch 3:  99%|▉| 4030/4091 [00:37<00:00, 107.43it/s, loss=5.26, v_num=0, loss/va\u001b[A\n",
      "Epoch 3:  99%|▉| 4056/4091 [00:37<00:00, 107.82it/s, loss=5.26, v_num=0, loss/va\u001b[A\n",
      "Epoch 3: 100%|█| 4091/4091 [00:37<00:00, 108.11it/s, loss=5.26, v_num=0, loss/va\u001b[A\n",
      "Epoch 4:  90%|▉| 3687/4091 [00:35<00:03, 104.09it/s, loss=5.24, v_num=0, loss/va\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                       | 0/404 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4:  90%|▉| 3692/4091 [00:35<00:03, 102.57it/s, loss=5.24, v_num=0, loss/va\u001b[A\n",
      "Epoch 4:  91%|▉| 3718/4091 [00:36<00:03, 103.00it/s, loss=5.24, v_num=0, loss/va\u001b[A\n",
      "Epoch 4:  92%|▉| 3744/4091 [00:36<00:03, 103.42it/s, loss=5.24, v_num=0, loss/va\u001b[A\n",
      "Epoch 4:  92%|▉| 3770/4091 [00:36<00:03, 103.84it/s, loss=5.24, v_num=0, loss/va\u001b[A\n",
      "Epoch 4:  93%|▉| 3796/4091 [00:36<00:02, 104.25it/s, loss=5.24, v_num=0, loss/va\u001b[A\n",
      "Epoch 4:  93%|▉| 3822/4091 [00:36<00:02, 104.66it/s, loss=5.24, v_num=0, loss/va\u001b[A\n",
      "Epoch 4:  94%|▉| 3848/4091 [00:36<00:02, 105.08it/s, loss=5.24, v_num=0, loss/va\u001b[A\n",
      "Epoch 4:  95%|▉| 3874/4091 [00:36<00:02, 105.47it/s, loss=5.24, v_num=0, loss/va\u001b[A\n",
      "Epoch 4:  95%|▉| 3900/4091 [00:36<00:01, 105.88it/s, loss=5.24, v_num=0, loss/va\u001b[A\n",
      "Epoch 4:  96%|▉| 3926/4091 [00:36<00:01, 106.28it/s, loss=5.24, v_num=0, loss/va\u001b[A\n",
      "Epoch 4:  97%|▉| 3952/4091 [00:37<00:01, 106.68it/s, loss=5.24, v_num=0, loss/va\u001b[A\n",
      "Epoch 4:  97%|▉| 3978/4091 [00:37<00:01, 107.07it/s, loss=5.24, v_num=0, loss/va\u001b[A\n",
      "Epoch 4:  98%|▉| 4004/4091 [00:37<00:00, 107.46it/s, loss=5.24, v_num=0, loss/va\u001b[A\n",
      "Epoch 4:  99%|▉| 4030/4091 [00:37<00:00, 107.85it/s, loss=5.24, v_num=0, loss/va\u001b[A\n",
      "Epoch 4:  99%|▉| 4056/4091 [00:37<00:00, 108.24it/s, loss=5.24, v_num=0, loss/va\u001b[A\n",
      "Epoch 4: 100%|▉| 4082/4091 [00:37<00:00, 108.63it/s, loss=5.24, v_num=0, loss/va\u001b[A\n",
      "Epoch 4: 100%|█| 4091/4091 [00:37<00:00, 108.50it/s, loss=5.24, v_num=0, loss/va\u001b[A\n",
      "Epoch 5:  90%|▉| 3687/4091 [00:35<00:03, 102.85it/s, loss=5.24, v_num=0, loss/va\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                       | 0/404 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5:  90%|▉| 3692/4091 [00:36<00:03, 101.36it/s, loss=5.24, v_num=0, loss/va\u001b[A\n",
      "Epoch 5:  91%|▉| 3718/4091 [00:36<00:03, 101.79it/s, loss=5.24, v_num=0, loss/va\u001b[A\n",
      "Epoch 5:  92%|▉| 3744/4091 [00:36<00:03, 102.20it/s, loss=5.24, v_num=0, loss/va\u001b[A\n",
      "Epoch 5:  92%|▉| 3770/4091 [00:36<00:03, 102.62it/s, loss=5.24, v_num=0, loss/va\u001b[A\n",
      "Epoch 5:  93%|▉| 3796/4091 [00:36<00:02, 103.03it/s, loss=5.24, v_num=0, loss/va\u001b[A\n",
      "Epoch 5:  93%|▉| 3822/4091 [00:36<00:02, 103.43it/s, loss=5.24, v_num=0, loss/va\u001b[A\n",
      "Epoch 5:  94%|▉| 3848/4091 [00:37<00:02, 103.84it/s, loss=5.24, v_num=0, loss/va\u001b[A\n",
      "Epoch 5:  95%|▉| 3874/4091 [00:37<00:02, 104.24it/s, loss=5.24, v_num=0, loss/va\u001b[A\n",
      "Epoch 5:  95%|▉| 3900/4091 [00:37<00:01, 104.65it/s, loss=5.24, v_num=0, loss/va\u001b[A\n",
      "Epoch 5:  96%|▉| 3926/4091 [00:37<00:01, 105.05it/s, loss=5.24, v_num=0, loss/va\u001b[A\n",
      "Epoch 5:  97%|▉| 3952/4091 [00:37<00:01, 105.45it/s, loss=5.24, v_num=0, loss/va\u001b[A\n",
      "Epoch 5:  97%|▉| 3978/4091 [00:37<00:01, 105.84it/s, loss=5.24, v_num=0, loss/va\u001b[A\n",
      "Epoch 5:  98%|▉| 4004/4091 [00:37<00:00, 106.24it/s, loss=5.24, v_num=0, loss/va\u001b[A\n",
      "Epoch 5:  99%|▉| 4030/4091 [00:37<00:00, 106.63it/s, loss=5.24, v_num=0, loss/va\u001b[A\n",
      "Epoch 5:  99%|▉| 4056/4091 [00:37<00:00, 107.02it/s, loss=5.24, v_num=0, loss/va\u001b[A\n",
      "Epoch 5: 100%|▉| 4082/4091 [00:38<00:00, 107.41it/s, loss=5.24, v_num=0, loss/va\u001b[A\n",
      "Epoch 5: 100%|█| 4091/4091 [00:38<00:00, 107.28it/s, loss=5.24, v_num=0, loss/va\u001b[A\n",
      "Epoch 6:  90%|▉| 3687/4091 [00:35<00:03, 103.63it/s, loss=5.11, v_num=0, loss/va\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                       | 0/404 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 6:  90%|▉| 3692/4091 [00:36<00:03, 102.10it/s, loss=5.11, v_num=0, loss/va\u001b[A\n",
      "Epoch 6:  91%|▉| 3720/4091 [00:36<00:03, 102.59it/s, loss=5.11, v_num=0, loss/va\u001b[A\n",
      "Epoch 6:  92%|▉| 3748/4091 [00:36<00:03, 103.03it/s, loss=5.11, v_num=0, loss/va\u001b[A\n",
      "Epoch 6:  92%|▉| 3776/4091 [00:36<00:03, 103.48it/s, loss=5.11, v_num=0, loss/va\u001b[A\n",
      "Epoch 6:  93%|▉| 3804/4091 [00:36<00:02, 103.92it/s, loss=5.11, v_num=0, loss/va\u001b[A\n",
      "Epoch 6:  94%|▉| 3832/4091 [00:36<00:02, 104.36it/s, loss=5.11, v_num=0, loss/va\u001b[A\n",
      "Epoch 6:  94%|▉| 3860/4091 [00:36<00:02, 104.80it/s, loss=5.11, v_num=0, loss/va\u001b[A\n",
      "Epoch 6:  95%|▉| 3888/4091 [00:36<00:01, 105.23it/s, loss=5.11, v_num=0, loss/va\u001b[A\n",
      "Validating:  50%|██████████████              | 202/404 [00:01<00:00, 222.94it/s]\u001b[A\n",
      "Epoch 6:  96%|▉| 3916/4091 [00:37<00:01, 105.65it/s, loss=5.11, v_num=0, loss/va\u001b[A\n",
      "Epoch 6:  96%|▉| 3944/4091 [00:37<00:01, 106.08it/s, loss=5.11, v_num=0, loss/va\u001b[A\n",
      "Epoch 6:  97%|▉| 3972/4091 [00:37<00:01, 106.49it/s, loss=5.11, v_num=0, loss/va\u001b[A\n",
      "Epoch 6:  98%|▉| 4000/4091 [00:37<00:00, 106.92it/s, loss=5.11, v_num=0, loss/va\u001b[A\n",
      "Epoch 6:  98%|▉| 4028/4091 [00:37<00:00, 107.34it/s, loss=5.11, v_num=0, loss/va\u001b[A\n",
      "Epoch 6:  99%|▉| 4056/4091 [00:37<00:00, 107.76it/s, loss=5.11, v_num=0, loss/va\u001b[A\n",
      "Epoch 6: 100%|▉| 4084/4091 [00:37<00:00, 108.18it/s, loss=5.11, v_num=0, loss/va\u001b[A\n",
      "Epoch 6: 100%|█| 4091/4091 [00:37<00:00, 108.00it/s, loss=5.11, v_num=0, loss/va\u001b[A\n",
      "Epoch 7:  90%|▉| 3687/4091 [00:35<00:03, 104.24it/s, loss=5.15, v_num=0, loss/va\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                       | 0/404 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 7:  90%|▉| 3696/4091 [00:35<00:03, 102.75it/s, loss=5.15, v_num=0, loss/va\u001b[A\n",
      "Epoch 7:  91%|▉| 3724/4091 [00:36<00:03, 103.22it/s, loss=5.15, v_num=0, loss/va\u001b[A\n",
      "Epoch 7:  92%|▉| 3752/4091 [00:36<00:03, 103.67it/s, loss=5.15, v_num=0, loss/va\u001b[A\n",
      "Epoch 7:  92%|▉| 3780/4091 [00:36<00:02, 104.12it/s, loss=5.15, v_num=0, loss/va\u001b[A\n",
      "Epoch 7:  93%|▉| 3808/4091 [00:36<00:02, 104.57it/s, loss=5.15, v_num=0, loss/va\u001b[A\n",
      "Epoch 7:  94%|▉| 3836/4091 [00:36<00:02, 105.01it/s, loss=5.15, v_num=0, loss/va\u001b[A\n",
      "Validating:  37%|██████████▍                 | 150/404 [00:01<00:01, 202.79it/s]\u001b[A\n",
      "Epoch 7:  94%|▉| 3864/4091 [00:36<00:02, 105.45it/s, loss=5.15, v_num=0, loss/va\u001b[A\n",
      "Epoch 7:  95%|▉| 3892/4091 [00:36<00:01, 105.88it/s, loss=5.15, v_num=0, loss/va\u001b[A\n",
      "Epoch 7:  96%|▉| 3920/4091 [00:36<00:01, 106.32it/s, loss=5.15, v_num=0, loss/va\u001b[A\n",
      "Epoch 7:  97%|▉| 3948/4091 [00:36<00:01, 106.75it/s, loss=5.15, v_num=0, loss/va\u001b[A\n",
      "Epoch 7:  97%|▉| 3976/4091 [00:37<00:01, 107.18it/s, loss=5.15, v_num=0, loss/va\u001b[A\n",
      "Epoch 7:  98%|▉| 4004/4091 [00:37<00:00, 107.60it/s, loss=5.15, v_num=0, loss/va\u001b[A\n",
      "Epoch 7:  99%|▉| 4032/4091 [00:37<00:00, 108.03it/s, loss=5.15, v_num=0, loss/va\u001b[A\n",
      "Epoch 7:  99%|▉| 4060/4091 [00:37<00:00, 108.44it/s, loss=5.15, v_num=0, loss/va\u001b[A\n",
      "Epoch 7: 100%|▉| 4088/4091 [00:37<00:00, 108.86it/s, loss=5.15, v_num=0, loss/va\u001b[A\n",
      "Epoch 7: 100%|█| 4091/4091 [00:37<00:00, 108.64it/s, loss=5.15, v_num=0, loss/va\u001b[A\n",
      "Epoch 8:  90%|▉| 3687/4091 [00:35<00:03, 103.89it/s, loss=5.09, v_num=0, loss/va\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                       | 0/404 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 8:  90%|▉| 3696/4091 [00:36<00:03, 102.42it/s, loss=5.09, v_num=0, loss/va\u001b[A\n",
      "Epoch 8:  91%|▉| 3724/4091 [00:36<00:03, 102.91it/s, loss=5.09, v_num=0, loss/va\u001b[A\n",
      "Epoch 8:  92%|▉| 3752/4091 [00:36<00:03, 103.35it/s, loss=5.09, v_num=0, loss/va\u001b[A\n",
      "Epoch 8:  92%|▉| 3780/4091 [00:36<00:02, 103.78it/s, loss=5.09, v_num=0, loss/va\u001b[A\n",
      "Epoch 8:  93%|▉| 3808/4091 [00:36<00:02, 104.23it/s, loss=5.09, v_num=0, loss/va\u001b[A\n",
      "Epoch 8:  94%|▉| 3836/4091 [00:36<00:02, 104.67it/s, loss=5.09, v_num=0, loss/va\u001b[A\n",
      "Validating:  37%|██████████▍                 | 150/404 [00:01<00:01, 201.79it/s]\u001b[A\n",
      "Epoch 8:  94%|▉| 3864/4091 [00:36<00:02, 105.11it/s, loss=5.09, v_num=0, loss/va\u001b[A\n",
      "Epoch 8:  95%|▉| 3892/4091 [00:36<00:01, 105.54it/s, loss=5.09, v_num=0, loss/va\u001b[A\n",
      "Epoch 8:  96%|▉| 3920/4091 [00:36<00:01, 105.97it/s, loss=5.09, v_num=0, loss/va\u001b[A\n",
      "Epoch 8:  97%|▉| 3948/4091 [00:37<00:01, 106.40it/s, loss=5.09, v_num=0, loss/va\u001b[A\n",
      "Epoch 8:  97%|▉| 3976/4091 [00:37<00:01, 106.84it/s, loss=5.09, v_num=0, loss/va\u001b[A\n",
      "Epoch 8:  98%|▉| 4004/4091 [00:37<00:00, 107.26it/s, loss=5.09, v_num=0, loss/va\u001b[A\n",
      "Epoch 8:  99%|▉| 4032/4091 [00:37<00:00, 107.68it/s, loss=5.09, v_num=0, loss/va\u001b[A\n",
      "Epoch 8:  99%|▉| 4060/4091 [00:37<00:00, 108.10it/s, loss=5.09, v_num=0, loss/va\u001b[A\n",
      "Epoch 8: 100%|▉| 4088/4091 [00:37<00:00, 108.52it/s, loss=5.09, v_num=0, loss/va\u001b[A\n",
      "Epoch 8: 100%|█| 4091/4091 [00:37<00:00, 108.32it/s, loss=5.09, v_num=0, loss/va\u001b[A\n",
      "Epoch 9:  90%|▉| 3687/4091 [00:35<00:03, 103.48it/s, loss=5.03, v_num=0, loss/va\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                       | 0/404 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 9:  90%|▉| 3696/4091 [00:36<00:03, 102.00it/s, loss=5.03, v_num=0, loss/va\u001b[A\n",
      "Epoch 9:  91%|▉| 3724/4091 [00:36<00:03, 102.48it/s, loss=5.03, v_num=0, loss/va\u001b[A\n",
      "Epoch 9:  92%|▉| 3752/4091 [00:36<00:03, 102.93it/s, loss=5.03, v_num=0, loss/va\u001b[A\n",
      "Epoch 9:  92%|▉| 3780/4091 [00:36<00:03, 103.37it/s, loss=5.03, v_num=0, loss/va\u001b[A\n",
      "Epoch 9:  93%|▉| 3808/4091 [00:36<00:02, 103.80it/s, loss=5.03, v_num=0, loss/va\u001b[A\n",
      "Epoch 9:  94%|▉| 3836/4091 [00:36<00:02, 104.24it/s, loss=5.03, v_num=0, loss/va\u001b[A\n",
      "Validating:  37%|██████████▍                 | 150/404 [00:01<00:01, 197.71it/s]\u001b[A\n",
      "Epoch 9:  94%|▉| 3864/4091 [00:36<00:02, 104.66it/s, loss=5.03, v_num=0, loss/va\u001b[A\n",
      "Epoch 9:  95%|▉| 3892/4091 [00:37<00:01, 105.10it/s, loss=5.03, v_num=0, loss/va\u001b[A\n",
      "Epoch 9:  96%|▉| 3920/4091 [00:37<00:01, 105.53it/s, loss=5.03, v_num=0, loss/va\u001b[A\n",
      "Epoch 9:  97%|▉| 3948/4091 [00:37<00:01, 105.96it/s, loss=5.03, v_num=0, loss/va\u001b[A\n",
      "Epoch 9:  97%|▉| 3976/4091 [00:37<00:01, 106.39it/s, loss=5.03, v_num=0, loss/va\u001b[A\n",
      "Epoch 9:  98%|▉| 4004/4091 [00:37<00:00, 106.82it/s, loss=5.03, v_num=0, loss/va\u001b[A\n",
      "Epoch 9:  99%|▉| 4032/4091 [00:37<00:00, 107.24it/s, loss=5.03, v_num=0, loss/va\u001b[A\n",
      "Epoch 9:  99%|▉| 4060/4091 [00:37<00:00, 107.66it/s, loss=5.03, v_num=0, loss/va\u001b[A\n",
      "Epoch 9: 100%|▉| 4088/4091 [00:37<00:00, 108.08it/s, loss=5.03, v_num=0, loss/va\u001b[A\n",
      "Epoch 9: 100%|█| 4091/4091 [00:37<00:00, 107.89it/s, loss=5.03, v_num=0, loss/va\u001b[A\n",
      "Epoch 10:  90%|▉| 3687/4091 [00:35<00:03, 102.80it/s, loss=5.02, v_num=0, loss/v\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                       | 0/404 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 10:  90%|▉| 3696/4091 [00:36<00:03, 101.34it/s, loss=5.02, v_num=0, loss/v\u001b[A\n",
      "Epoch 10:  91%|▉| 3724/4091 [00:36<00:03, 101.80it/s, loss=5.02, v_num=0, loss/v\u001b[A\n",
      "Epoch 10:  92%|▉| 3752/4091 [00:36<00:03, 102.25it/s, loss=5.02, v_num=0, loss/v\u001b[A\n",
      "Epoch 10:  92%|▉| 3780/4091 [00:36<00:03, 102.68it/s, loss=5.02, v_num=0, loss/v\u001b[A\n",
      "Epoch 10:  93%|▉| 3808/4091 [00:36<00:02, 103.13it/s, loss=5.02, v_num=0, loss/v\u001b[A\n",
      "Epoch 10:  94%|▉| 3836/4091 [00:37<00:02, 103.57it/s, loss=5.02, v_num=0, loss/v\u001b[A\n",
      "Validating:  37%|██████████▍                 | 150/404 [00:01<00:01, 200.39it/s]\u001b[A\n",
      "Epoch 10:  94%|▉| 3864/4091 [00:37<00:02, 103.99it/s, loss=5.02, v_num=0, loss/v\u001b[A\n",
      "Epoch 10:  95%|▉| 3892/4091 [00:37<00:01, 104.42it/s, loss=5.02, v_num=0, loss/v\u001b[A\n",
      "Epoch 10:  96%|▉| 3920/4091 [00:37<00:01, 104.86it/s, loss=5.02, v_num=0, loss/v\u001b[A\n",
      "Epoch 10:  97%|▉| 3948/4091 [00:37<00:01, 105.29it/s, loss=5.02, v_num=0, loss/v\u001b[A\n",
      "Epoch 10:  97%|▉| 3976/4091 [00:37<00:01, 105.72it/s, loss=5.02, v_num=0, loss/v\u001b[A\n",
      "Epoch 10:  98%|▉| 4004/4091 [00:37<00:00, 106.14it/s, loss=5.02, v_num=0, loss/v\u001b[A\n",
      "Epoch 10:  99%|▉| 4032/4091 [00:37<00:00, 106.57it/s, loss=5.02, v_num=0, loss/v\u001b[A\n",
      "Epoch 10:  99%|▉| 4060/4091 [00:37<00:00, 106.99it/s, loss=5.02, v_num=0, loss/v\u001b[A\n",
      "Validating:  93%|█████████████████████████▉  | 375/404 [00:02<00:00, 245.38it/s]\u001b[A\n",
      "Epoch 10: 100%|█| 4091/4091 [00:38<00:00, 107.18it/s, loss=5.02, v_num=0, loss/v\u001b[A\n",
      "Epoch 11:  90%|▉| 3687/4091 [00:35<00:03, 103.29it/s, loss=5, v_num=0, loss/vali\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                       | 0/404 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 11:  90%|▉| 3696/4091 [00:36<00:03, 101.86it/s, loss=5, v_num=0, loss/vali\u001b[A\n",
      "Epoch 11:  91%|▉| 3724/4091 [00:36<00:03, 102.31it/s, loss=5, v_num=0, loss/vali\u001b[A\n",
      "Epoch 11:  92%|▉| 3752/4091 [00:36<00:03, 102.76it/s, loss=5, v_num=0, loss/vali\u001b[A\n",
      "Epoch 11:  92%|▉| 3780/4091 [00:36<00:03, 103.22it/s, loss=5, v_num=0, loss/vali\u001b[A\n",
      "Epoch 11:  93%|▉| 3808/4091 [00:36<00:02, 103.67it/s, loss=5, v_num=0, loss/vali\u001b[A\n",
      "Epoch 11:  94%|▉| 3836/4091 [00:36<00:02, 104.11it/s, loss=5, v_num=0, loss/vali\u001b[A\n",
      "Epoch 11:  94%|▉| 3864/4091 [00:36<00:02, 104.55it/s, loss=5, v_num=0, loss/vali\u001b[A\n",
      "Validating:  44%|████████████▎               | 178/404 [00:01<00:01, 216.78it/s]\u001b[A\n",
      "Epoch 11:  95%|▉| 3892/4091 [00:37<00:01, 104.98it/s, loss=5, v_num=0, loss/vali\u001b[A\n",
      "Epoch 11:  96%|▉| 3920/4091 [00:37<00:01, 105.42it/s, loss=5, v_num=0, loss/vali\u001b[A\n",
      "Epoch 11:  97%|▉| 3948/4091 [00:37<00:01, 105.83it/s, loss=5, v_num=0, loss/vali\u001b[A\n",
      "Epoch 11:  97%|▉| 3976/4091 [00:37<00:01, 106.26it/s, loss=5, v_num=0, loss/vali\u001b[A\n",
      "Epoch 11:  98%|▉| 4004/4091 [00:37<00:00, 106.68it/s, loss=5, v_num=0, loss/vali\u001b[A\n",
      "Epoch 11:  99%|▉| 4032/4091 [00:37<00:00, 107.10it/s, loss=5, v_num=0, loss/vali\u001b[A\n",
      "Epoch 11:  99%|▉| 4060/4091 [00:37<00:00, 107.52it/s, loss=5, v_num=0, loss/vali\u001b[A\n",
      "Epoch 11: 100%|▉| 4088/4091 [00:37<00:00, 107.93it/s, loss=5, v_num=0, loss/vali\u001b[A\n",
      "Epoch 11: 100%|█| 4091/4091 [00:37<00:00, 107.71it/s, loss=5, v_num=0, loss/vali\u001b[A\n",
      "Epoch 12:  90%|▉| 3687/4091 [00:35<00:03, 103.32it/s, loss=4.93, v_num=0, loss/v\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                       | 0/404 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 12:  90%|▉| 3696/4091 [00:36<00:03, 101.87it/s, loss=4.93, v_num=0, loss/v\u001b[A\n",
      "Epoch 12:  91%|▉| 3724/4091 [00:36<00:03, 102.33it/s, loss=4.93, v_num=0, loss/v\u001b[A\n",
      "Epoch 12:  92%|▉| 3752/4091 [00:36<00:03, 102.77it/s, loss=4.93, v_num=0, loss/v\u001b[A\n",
      "Epoch 12:  92%|▉| 3780/4091 [00:36<00:03, 103.21it/s, loss=4.93, v_num=0, loss/v\u001b[A\n",
      "Epoch 12:  93%|▉| 3808/4091 [00:36<00:02, 103.64it/s, loss=4.93, v_num=0, loss/v\u001b[A\n",
      "Epoch 12:  94%|▉| 3836/4091 [00:36<00:02, 104.09it/s, loss=4.93, v_num=0, loss/v\u001b[A\n",
      "Validating:  37%|██████████▎                 | 149/404 [00:01<00:01, 199.79it/s]\u001b[A\n",
      "Epoch 12:  94%|▉| 3864/4091 [00:36<00:02, 104.52it/s, loss=4.93, v_num=0, loss/v\u001b[A\n",
      "Epoch 12:  95%|▉| 3892/4091 [00:37<00:01, 104.96it/s, loss=4.93, v_num=0, loss/v\u001b[A\n",
      "Epoch 12:  96%|▉| 3920/4091 [00:37<00:01, 105.39it/s, loss=4.93, v_num=0, loss/v\u001b[A\n",
      "Epoch 12:  97%|▉| 3948/4091 [00:37<00:01, 105.82it/s, loss=4.93, v_num=0, loss/v\u001b[A\n",
      "Epoch 12:  97%|▉| 3976/4091 [00:37<00:01, 106.25it/s, loss=4.93, v_num=0, loss/v\u001b[A\n",
      "Epoch 12:  98%|▉| 4004/4091 [00:37<00:00, 106.68it/s, loss=4.93, v_num=0, loss/v\u001b[A\n",
      "Epoch 12:  99%|▉| 4032/4091 [00:37<00:00, 107.10it/s, loss=4.93, v_num=0, loss/v\u001b[A\n",
      "Epoch 12:  99%|▉| 4060/4091 [00:37<00:00, 107.52it/s, loss=4.93, v_num=0, loss/v\u001b[A\n",
      "Validating:  93%|█████████████████████████▉  | 374/404 [00:02<00:00, 244.64it/s]\u001b[A\n",
      "Epoch 12: 100%|█| 4091/4091 [00:37<00:00, 107.72it/s, loss=4.93, v_num=0, loss/v\u001b[A\n",
      "Epoch 13:  90%|▉| 3687/4091 [00:35<00:03, 103.51it/s, loss=4.95, v_num=0, loss/v\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                       | 0/404 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 13:  90%|▉| 3696/4091 [00:36<00:03, 102.06it/s, loss=4.95, v_num=0, loss/v\u001b[A\n",
      "Epoch 13:  91%|▉| 3724/4091 [00:36<00:03, 102.54it/s, loss=4.95, v_num=0, loss/v\u001b[A\n",
      "Epoch 13:  92%|▉| 3752/4091 [00:36<00:03, 102.99it/s, loss=4.95, v_num=0, loss/v\u001b[A\n",
      "Epoch 13:  92%|▉| 3780/4091 [00:36<00:03, 103.44it/s, loss=4.95, v_num=0, loss/v\u001b[A\n",
      "Epoch 13:  93%|▉| 3808/4091 [00:36<00:02, 103.88it/s, loss=4.95, v_num=0, loss/v\u001b[A\n",
      "Epoch 13:  94%|▉| 3836/4091 [00:36<00:02, 104.32it/s, loss=4.95, v_num=0, loss/v\u001b[A\n",
      "Epoch 13:  94%|▉| 3864/4091 [00:36<00:02, 104.76it/s, loss=4.95, v_num=0, loss/v\u001b[A\n",
      "Validating:  44%|████████████▎               | 177/404 [00:01<00:01, 216.26it/s]\u001b[A\n",
      "Epoch 13:  95%|▉| 3892/4091 [00:36<00:01, 105.19it/s, loss=4.95, v_num=0, loss/v\u001b[A\n",
      "Epoch 13:  96%|▉| 3920/4091 [00:37<00:01, 105.63it/s, loss=4.95, v_num=0, loss/v\u001b[A\n",
      "Epoch 13:  97%|▉| 3948/4091 [00:37<00:01, 106.06it/s, loss=4.95, v_num=0, loss/v\u001b[A\n",
      "Epoch 13:  97%|▉| 3976/4091 [00:37<00:01, 106.48it/s, loss=4.95, v_num=0, loss/v\u001b[A\n",
      "Epoch 13:  98%|▉| 4004/4091 [00:37<00:00, 106.90it/s, loss=4.95, v_num=0, loss/v\u001b[A\n",
      "Epoch 13:  99%|▉| 4032/4091 [00:37<00:00, 107.32it/s, loss=4.95, v_num=0, loss/v\u001b[A\n",
      "Epoch 13:  99%|▉| 4060/4091 [00:37<00:00, 107.74it/s, loss=4.95, v_num=0, loss/v\u001b[A\n",
      "Epoch 13: 100%|▉| 4088/4091 [00:37<00:00, 108.17it/s, loss=4.95, v_num=0, loss/v\u001b[A\n",
      "Epoch 13: 100%|█| 4091/4091 [00:37<00:00, 107.96it/s, loss=4.95, v_num=0, loss/v\u001b[A\n",
      "Epoch 14:  90%|▉| 3687/4091 [00:35<00:03, 102.71it/s, loss=4.95, v_num=0, loss/v\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                       | 0/404 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 14:  90%|▉| 3696/4091 [00:36<00:03, 101.30it/s, loss=4.95, v_num=0, loss/v\u001b[A\n",
      "Epoch 14:  91%|▉| 3724/4091 [00:36<00:03, 101.75it/s, loss=4.95, v_num=0, loss/v\u001b[A\n",
      "Epoch 14:  92%|▉| 3752/4091 [00:36<00:03, 102.19it/s, loss=4.95, v_num=0, loss/v\u001b[A\n",
      "Epoch 14:  92%|▉| 3780/4091 [00:36<00:03, 102.63it/s, loss=4.95, v_num=0, loss/v\u001b[A\n",
      "Epoch 14:  93%|▉| 3808/4091 [00:36<00:02, 103.07it/s, loss=4.95, v_num=0, loss/v\u001b[A\n",
      "Epoch 14:  94%|▉| 3836/4091 [00:37<00:02, 103.51it/s, loss=4.95, v_num=0, loss/v\u001b[A\n",
      "Validating:  37%|██████████▍                 | 150/404 [00:01<00:01, 201.32it/s]\u001b[A\n",
      "Epoch 14:  94%|▉| 3864/4091 [00:37<00:02, 103.95it/s, loss=4.95, v_num=0, loss/v\u001b[A\n",
      "Epoch 14:  95%|▉| 3892/4091 [00:37<00:01, 104.38it/s, loss=4.95, v_num=0, loss/v\u001b[A\n",
      "Epoch 14:  96%|▉| 3920/4091 [00:37<00:01, 104.81it/s, loss=4.95, v_num=0, loss/v\u001b[A\n",
      "Epoch 14:  97%|▉| 3948/4091 [00:37<00:01, 105.24it/s, loss=4.95, v_num=0, loss/v\u001b[A\n",
      "Epoch 14:  97%|▉| 3976/4091 [00:37<00:01, 105.66it/s, loss=4.95, v_num=0, loss/v\u001b[A\n",
      "Epoch 14:  98%|▉| 4004/4091 [00:37<00:00, 106.08it/s, loss=4.95, v_num=0, loss/v\u001b[A\n",
      "Epoch 14:  99%|▉| 4032/4091 [00:37<00:00, 106.50it/s, loss=4.95, v_num=0, loss/v\u001b[A\n",
      "Epoch 14:  99%|▉| 4060/4091 [00:37<00:00, 106.92it/s, loss=4.95, v_num=0, loss/v\u001b[A\n",
      "Epoch 14: 100%|▉| 4088/4091 [00:38<00:00, 107.35it/s, loss=4.95, v_num=0, loss/v\u001b[A\n",
      "Epoch 14: 100%|█| 4091/4091 [00:38<00:00, 107.13it/s, loss=4.95, v_num=0, loss/v\u001b[A\n",
      "Epoch 15:  90%|▉| 3687/4091 [00:35<00:03, 103.05it/s, loss=4.92, v_num=0, loss/v\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                       | 0/404 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 15:  90%|▉| 3696/4091 [00:36<00:03, 101.63it/s, loss=4.92, v_num=0, loss/v\u001b[A\n",
      "Epoch 15:  91%|▉| 3724/4091 [00:36<00:03, 102.08it/s, loss=4.92, v_num=0, loss/v\u001b[A\n",
      "Epoch 15:  92%|▉| 3752/4091 [00:36<00:03, 102.52it/s, loss=4.92, v_num=0, loss/v\u001b[A\n",
      "Epoch 15:  92%|▉| 3780/4091 [00:36<00:03, 102.97it/s, loss=4.92, v_num=0, loss/v\u001b[A\n",
      "Epoch 15:  93%|▉| 3808/4091 [00:36<00:02, 103.40it/s, loss=4.92, v_num=0, loss/v\u001b[A\n",
      "Epoch 15:  94%|▉| 3836/4091 [00:36<00:02, 103.84it/s, loss=4.92, v_num=0, loss/v\u001b[A\n",
      "Validating:  37%|██████████▎                 | 149/404 [00:01<00:01, 200.98it/s]\u001b[A\n",
      "Epoch 15:  94%|▉| 3864/4091 [00:37<00:02, 104.28it/s, loss=4.92, v_num=0, loss/v\u001b[A\n",
      "Epoch 15:  95%|▉| 3892/4091 [00:37<00:01, 104.71it/s, loss=4.92, v_num=0, loss/v\u001b[A\n",
      "Epoch 15:  96%|▉| 3920/4091 [00:37<00:01, 105.14it/s, loss=4.92, v_num=0, loss/v\u001b[A\n",
      "Epoch 15:  97%|▉| 3948/4091 [00:37<00:01, 105.57it/s, loss=4.92, v_num=0, loss/v\u001b[A\n",
      "Epoch 15:  97%|▉| 3976/4091 [00:37<00:01, 106.00it/s, loss=4.92, v_num=0, loss/v\u001b[A\n",
      "Epoch 15:  98%|▉| 4004/4091 [00:37<00:00, 106.42it/s, loss=4.92, v_num=0, loss/v\u001b[A\n",
      "Epoch 15:  99%|▉| 4032/4091 [00:37<00:00, 106.83it/s, loss=4.92, v_num=0, loss/v\u001b[A\n",
      "Epoch 15:  99%|▉| 4060/4091 [00:37<00:00, 107.25it/s, loss=4.92, v_num=0, loss/v\u001b[A\n",
      "Epoch 15: 100%|▉| 4088/4091 [00:37<00:00, 107.68it/s, loss=4.92, v_num=0, loss/v\u001b[A\n",
      "Epoch 15: 100%|█| 4091/4091 [00:38<00:00, 107.47it/s, loss=4.92, v_num=0, loss/v\u001b[A\n",
      "Epoch 16:  90%|▉| 3687/4091 [00:35<00:03, 103.56it/s, loss=4.96, v_num=0, loss/v\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                       | 0/404 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 16:  90%|▉| 3696/4091 [00:36<00:03, 102.13it/s, loss=4.96, v_num=0, loss/v\u001b[A\n",
      "Epoch 16:  91%|▉| 3724/4091 [00:36<00:03, 102.58it/s, loss=4.96, v_num=0, loss/v\u001b[A\n",
      "Epoch 16:  92%|▉| 3752/4091 [00:36<00:03, 103.02it/s, loss=4.96, v_num=0, loss/v\u001b[A\n",
      "Epoch 16:  92%|▉| 3780/4091 [00:36<00:03, 103.46it/s, loss=4.96, v_num=0, loss/v\u001b[A\n",
      "Epoch 16:  93%|▉| 3808/4091 [00:36<00:02, 103.90it/s, loss=4.96, v_num=0, loss/v\u001b[A\n",
      "Epoch 16:  94%|▉| 3836/4091 [00:36<00:02, 104.34it/s, loss=4.96, v_num=0, loss/v\u001b[A\n",
      "Epoch 16:  94%|▉| 3864/4091 [00:36<00:02, 104.78it/s, loss=4.96, v_num=0, loss/v\u001b[A\n",
      "Validating:  44%|████████████▎               | 177/404 [00:01<00:01, 213.41it/s]\u001b[A\n",
      "Epoch 16:  95%|▉| 3892/4091 [00:36<00:01, 105.20it/s, loss=4.96, v_num=0, loss/v\u001b[A\n",
      "Epoch 16:  96%|▉| 3920/4091 [00:37<00:01, 105.64it/s, loss=4.96, v_num=0, loss/v\u001b[A\n",
      "Epoch 16:  97%|▉| 3948/4091 [00:37<00:01, 106.07it/s, loss=4.96, v_num=0, loss/v\u001b[A\n",
      "Epoch 16:  97%|▉| 3976/4091 [00:37<00:01, 106.49it/s, loss=4.96, v_num=0, loss/v\u001b[A\n",
      "Epoch 16:  98%|▉| 4004/4091 [00:37<00:00, 106.92it/s, loss=4.96, v_num=0, loss/v\u001b[A\n",
      "Epoch 16:  99%|▉| 4032/4091 [00:37<00:00, 107.34it/s, loss=4.96, v_num=0, loss/v\u001b[A\n",
      "Epoch 16:  99%|▉| 4060/4091 [00:37<00:00, 107.75it/s, loss=4.96, v_num=0, loss/v\u001b[A\n",
      "Epoch 16: 100%|▉| 4088/4091 [00:37<00:00, 108.18it/s, loss=4.96, v_num=0, loss/v\u001b[A\n",
      "Epoch 16: 100%|█| 4091/4091 [00:37<00:00, 107.94it/s, loss=4.96, v_num=0, loss/v\u001b[A\n",
      "Epoch 17:  90%|▉| 3687/4091 [00:35<00:03, 103.69it/s, loss=4.93, v_num=0, loss/v\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                       | 0/404 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 17:  90%|▉| 3696/4091 [00:36<00:03, 102.23it/s, loss=4.93, v_num=0, loss/v\u001b[A\n",
      "Epoch 17:  91%|▉| 3724/4091 [00:36<00:03, 102.70it/s, loss=4.93, v_num=0, loss/v\u001b[A\n",
      "Epoch 17:  92%|▉| 3752/4091 [00:36<00:03, 103.14it/s, loss=4.93, v_num=0, loss/v\u001b[A\n",
      "Epoch 17:  92%|▉| 3780/4091 [00:36<00:03, 103.59it/s, loss=4.93, v_num=0, loss/v\u001b[A\n",
      "Epoch 17:  93%|▉| 3808/4091 [00:36<00:02, 104.04it/s, loss=4.93, v_num=0, loss/v\u001b[A\n",
      "Epoch 17:  94%|▉| 3836/4091 [00:36<00:02, 104.47it/s, loss=4.93, v_num=0, loss/v\u001b[A\n",
      "Validating:  37%|██████████▍                 | 151/404 [00:01<00:01, 200.43it/s]\u001b[A\n",
      "Epoch 17:  94%|▉| 3864/4091 [00:36<00:02, 104.90it/s, loss=4.93, v_num=0, loss/v\u001b[A\n",
      "Epoch 17:  95%|▉| 3892/4091 [00:36<00:01, 105.33it/s, loss=4.93, v_num=0, loss/v\u001b[A\n",
      "Epoch 17:  96%|▉| 3920/4091 [00:37<00:01, 105.75it/s, loss=4.93, v_num=0, loss/v\u001b[A\n",
      "Epoch 17:  97%|▉| 3948/4091 [00:37<00:01, 106.18it/s, loss=4.93, v_num=0, loss/v\u001b[A\n",
      "Epoch 17:  97%|▉| 3976/4091 [00:37<00:01, 106.61it/s, loss=4.93, v_num=0, loss/v\u001b[A\n",
      "Epoch 17:  98%|▉| 4004/4091 [00:37<00:00, 107.03it/s, loss=4.93, v_num=0, loss/v\u001b[A\n",
      "Epoch 17:  99%|▉| 4032/4091 [00:37<00:00, 107.46it/s, loss=4.93, v_num=0, loss/v\u001b[A\n",
      "Epoch 17:  99%|▉| 4060/4091 [00:37<00:00, 107.87it/s, loss=4.93, v_num=0, loss/v\u001b[A\n",
      "Epoch 17: 100%|▉| 4088/4091 [00:37<00:00, 108.30it/s, loss=4.93, v_num=0, loss/v\u001b[A\n",
      "Epoch 17: 100%|█| 4091/4091 [00:37<00:00, 108.10it/s, loss=4.93, v_num=0, loss/v\u001b[A\n",
      "Epoch 18:  90%|▉| 3687/4091 [00:35<00:03, 103.94it/s, loss=4.94, v_num=0, loss/v\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                       | 0/404 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 18:  90%|▉| 3696/4091 [00:36<00:03, 102.47it/s, loss=4.94, v_num=0, loss/v\u001b[A\n",
      "Epoch 18:  91%|▉| 3724/4091 [00:36<00:03, 102.92it/s, loss=4.94, v_num=0, loss/v\u001b[A\n",
      "Epoch 18:  92%|▉| 3752/4091 [00:36<00:03, 103.36it/s, loss=4.94, v_num=0, loss/v\u001b[A\n",
      "Epoch 18:  92%|▉| 3780/4091 [00:36<00:02, 103.80it/s, loss=4.94, v_num=0, loss/v\u001b[A\n",
      "Epoch 18:  93%|▉| 3808/4091 [00:36<00:02, 104.25it/s, loss=4.94, v_num=0, loss/v\u001b[A\n",
      "Epoch 18:  94%|▉| 3836/4091 [00:36<00:02, 104.69it/s, loss=4.94, v_num=0, loss/v\u001b[A\n",
      "Validating:  37%|██████████▍                 | 150/404 [00:01<00:01, 200.87it/s]\u001b[A\n",
      "Epoch 18:  94%|▉| 3864/4091 [00:36<00:02, 105.12it/s, loss=4.94, v_num=0, loss/v\u001b[A\n",
      "Epoch 18:  95%|▉| 3892/4091 [00:36<00:01, 105.56it/s, loss=4.94, v_num=0, loss/v\u001b[A\n",
      "Epoch 18:  96%|▉| 3920/4091 [00:36<00:01, 105.99it/s, loss=4.94, v_num=0, loss/v\u001b[A\n",
      "Epoch 18:  97%|▉| 3948/4091 [00:37<00:01, 106.42it/s, loss=4.94, v_num=0, loss/v\u001b[A\n",
      "Epoch 18:  97%|▉| 3976/4091 [00:37<00:01, 106.84it/s, loss=4.94, v_num=0, loss/v\u001b[A\n",
      "Epoch 18:  98%|▉| 4004/4091 [00:37<00:00, 107.27it/s, loss=4.94, v_num=0, loss/v\u001b[A\n",
      "Epoch 18:  99%|▉| 4032/4091 [00:37<00:00, 107.69it/s, loss=4.94, v_num=0, loss/v\u001b[A\n",
      "Epoch 18:  99%|▉| 4060/4091 [00:37<00:00, 108.12it/s, loss=4.94, v_num=0, loss/v\u001b[A\n",
      "Epoch 18: 100%|▉| 4088/4091 [00:37<00:00, 108.54it/s, loss=4.94, v_num=0, loss/v\u001b[A\n",
      "Epoch 18: 100%|█| 4091/4091 [00:37<00:00, 108.32it/s, loss=4.94, v_num=0, loss/v\u001b[A\n",
      "Epoch 19:  90%|▉| 3687/4091 [00:35<00:03, 102.75it/s, loss=4.94, v_num=0, loss/v\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                       | 0/404 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 19:  90%|▉| 3696/4091 [00:36<00:03, 101.31it/s, loss=4.94, v_num=0, loss/v\u001b[A\n",
      "Epoch 19:  91%|▉| 3724/4091 [00:36<00:03, 101.77it/s, loss=4.94, v_num=0, loss/v\u001b[A\n",
      "Epoch 19:  92%|▉| 3752/4091 [00:36<00:03, 102.21it/s, loss=4.94, v_num=0, loss/v\u001b[A\n",
      "Epoch 19:  92%|▉| 3780/4091 [00:36<00:03, 102.64it/s, loss=4.94, v_num=0, loss/v\u001b[A\n",
      "Epoch 19:  93%|▉| 3808/4091 [00:36<00:02, 103.09it/s, loss=4.94, v_num=0, loss/v\u001b[A\n",
      "Epoch 19:  94%|▉| 3836/4091 [00:37<00:02, 103.52it/s, loss=4.94, v_num=0, loss/v\u001b[A\n",
      "Validating:  37%|██████████▍                 | 150/404 [00:01<00:01, 198.34it/s]\u001b[A\n",
      "Epoch 19:  94%|▉| 3864/4091 [00:37<00:02, 103.94it/s, loss=4.94, v_num=0, loss/v\u001b[A\n",
      "Epoch 19:  95%|▉| 3892/4091 [00:37<00:01, 104.37it/s, loss=4.94, v_num=0, loss/v\u001b[A\n",
      "Epoch 19:  96%|▉| 3920/4091 [00:37<00:01, 104.81it/s, loss=4.94, v_num=0, loss/v\u001b[A\n",
      "Epoch 19:  97%|▉| 3948/4091 [00:37<00:01, 105.24it/s, loss=4.94, v_num=0, loss/v\u001b[A\n",
      "Epoch 19:  97%|▉| 3976/4091 [00:37<00:01, 105.66it/s, loss=4.94, v_num=0, loss/v\u001b[A\n",
      "Epoch 19:  98%|▉| 4004/4091 [00:37<00:00, 106.09it/s, loss=4.94, v_num=0, loss/v\u001b[A\n",
      "Epoch 19:  99%|▉| 4032/4091 [00:37<00:00, 106.51it/s, loss=4.94, v_num=0, loss/v\u001b[A\n",
      "Epoch 19:  99%|▉| 4060/4091 [00:37<00:00, 106.93it/s, loss=4.94, v_num=0, loss/v\u001b[A\n",
      "Epoch 19: 100%|▉| 4088/4091 [00:38<00:00, 107.35it/s, loss=4.94, v_num=0, loss/v\u001b[A\n",
      "Epoch 19: 100%|█| 4091/4091 [00:38<00:00, 107.13it/s, loss=4.94, v_num=0, loss/v\u001b[A\n",
      "Epoch 19: 100%|█| 4091/4091 [00:38<00:00, 107.03it/s, loss=4.94, v_num=0, loss/v\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing:  97%|██████████████████████████████▏| 451/463 [00:02<00:00, 245.98it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'loss/test': 4.6080121994018555, 'perplexity/test': 102.39926147460938}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|███████████████████████████████| 463/463 [00:02<00:00, 183.32it/s]\n",
      "[{'loss/test': 4.6080121994018555, 'perplexity/test': 102.39926147460938}]\n"
     ]
    }
   ],
   "source": [
    "# Train RNN\n",
    "vocab_size = len(word_freqs)\n",
    "data_module = TextDateModule(train, valid, test)\n",
    "model = TextLightningModule(vocab_size)\n",
    "\n",
    "tb_logger = pl_loggers.TensorBoardLogger(\"./lightning_logs/\", name=\"network_1\")\n",
    "trainer = pl.Trainer(logger=tb_logger, max_epochs=20, gpus=1)\n",
    "trainer.fit(model, data_module)\n",
    "\n",
    "result = trainer.test(model, data_module)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1f50902-6c35-48b3-9dbd-dc548b7655d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextLSTMModule(pl.LightningModule):\n",
    "    \"\"\"LSTM modeule.\"\"\"\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.num_layers = 2\n",
    "        self.hidden_size = 100 #200\n",
    "        self.embedding_size = 100\n",
    "        self.vocab_size = vocab_size\n",
    "        \n",
    "        # embedding\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_size)\n",
    "        nn.init.uniform_(self.embedding.weight, -0.1, 0.1)\n",
    "        #layers\n",
    "        self.lstm = nn.LSTM(self.embedding_size, self.hidden_size, self.num_layers, batch_first=True)\n",
    "        self.out_fc = nn.Linear(self.hidden_size, vocab_size)\n",
    "        # loss funciton\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        \n",
    "    \n",
    "    def forward(self, data, hidden, cell):\n",
    "        embedding = self.dropout(self.embedding(data))\n",
    "        output, hidden = self.lstm(embedding, (hidden, cell))\n",
    "        output = self.out_fc(output)\n",
    "        return output.view(-1, self.vocab_size), (hidden, cell)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.SGD(self.parameters(), lr=5)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x,y = batch\n",
    "        y = y.view(-1)\n",
    "        \n",
    "        hidden = torch.zeros(self.num_layers, 20, self.hidden_size).to(self.device)\n",
    "        cell = torch.zeros(self.num_layers, 20, self.hidden_size).to(self.device)\n",
    "        output, (hidden, cell) = self.forward(x, hidden, cell)\n",
    "        loss = self.loss(output, y)\n",
    "        perplexity = math.exp(loss.item())\n",
    "        \n",
    "        tensorboard_logs = {'perplexity': {'train': perplexity}, 'loss': {'train': loss.detach()}}\n",
    "        self.log(\"loss/train\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"perplexity/train\", perplexity, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return {\"loss\": loss, \"log\": tensorboard_logs}\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x,y = batch\n",
    "        y = y.view(-1)\n",
    "        \n",
    "        hidden = torch.zeros(self.num_layers, 20, self.hidden_size).to(self.device)\n",
    "        cell = torch.zeros(self.num_layers, 20, self.hidden_size).to(self.device)\n",
    "        output, (hidden, cell) = self.forward(x, hidden, cell)\n",
    "        loss = self.loss(output, y)\n",
    "        perplexity = math.exp(loss.item())\n",
    "        \n",
    "        tensorboard_logs = {'perplexity': {'valid': perplexity}, 'loss': {'valid': loss.detach()}}\n",
    "        self.log(\"loss/valid\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"perplexity/valid\", perplexity, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return {\"loss\": loss, \"log\": tensorboard_logs}\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x,y = batch\n",
    "        y = y.view(-1)\n",
    "        \n",
    "        hidden = torch.zeros(self.num_layers, 20, self.hidden_size).to(self.device)\n",
    "        cell = torch.zeros(self.num_layers, 20, self.hidden_size).to(self.device)\n",
    "        output, (hidden, cell) = self.forward(x, hidden, cell)\n",
    "        loss = self.loss(output, y)\n",
    "        perplexity = math.exp(loss.item())\n",
    "        \n",
    "        tensorboard_logs = {'perplexity': {'test': perplexity}, 'loss': {'test': loss.detach()}}\n",
    "        self.log(\"loss/test\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"perplexity/test\", perplexity, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return {\"loss\": loss, \"log\": tensorboard_logs}\n",
    "\n",
    "    def init_hidden(self, batch_size = 20):\n",
    "        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "        cell = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b402e09f-e879-4a63-8c70-5c4778be3317",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "/home/ml/.pyenv/versions/3.9.7/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:469: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
      "  rank_zero_deprecation(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Missing logger folder: ./lightning_logs/network_2\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | embedding | Embedding        | 2.9 M \n",
      "1 | lstm      | LSTM             | 161 K \n",
      "2 | out_fc    | Linear           | 2.9 M \n",
      "3 | loss      | CrossEntropyLoss | 0     \n",
      "4 | dropout   | Dropout          | 0     \n",
      "-----------------------------------------------\n",
      "6.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.0 M     Total params\n",
      "23.884    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  90%|█████████ | 3687/4091 [00:37<00:04, 99.30it/s, loss=5.33, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                       | 0/404 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  90%|█████████ | 3694/4091 [00:37<00:04, 97.91it/s, loss=5.33, v_num=0]\u001b[A\n",
      "Epoch 0:  91%|█████████ | 3721/4091 [00:37<00:03, 98.36it/s, loss=5.33, v_num=0]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 3748/4091 [00:37<00:03, 98.79it/s, loss=5.33, v_num=0]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 3775/4091 [00:38<00:03, 99.21it/s, loss=5.33, v_num=0]\u001b[A\n",
      "Epoch 0:  93%|█████████▎| 3802/4091 [00:38<00:02, 99.63it/s, loss=5.33, v_num=0]\u001b[A\n",
      "Epoch 0:  94%|████████▍| 3829/4091 [00:38<00:02, 100.05it/s, loss=5.33, v_num=0]\u001b[A\n",
      "Epoch 0:  94%|████████▍| 3856/4091 [00:38<00:02, 100.47it/s, loss=5.33, v_num=0]\u001b[A\n",
      "Epoch 0:  95%|████████▌| 3883/4091 [00:38<00:02, 100.87it/s, loss=5.33, v_num=0]\u001b[A\n",
      "Epoch 0:  96%|████████▌| 3910/4091 [00:38<00:01, 101.28it/s, loss=5.33, v_num=0]\u001b[A\n",
      "Validating:  55%|███████████████▌            | 224/404 [00:01<00:00, 227.90it/s]\u001b[A\n",
      "Epoch 0:  96%|████████▋| 3937/4091 [00:38<00:01, 101.69it/s, loss=5.33, v_num=0]\u001b[A\n",
      "Epoch 0:  97%|████████▋| 3964/4091 [00:38<00:01, 102.10it/s, loss=5.33, v_num=0]\u001b[A\n",
      "Epoch 0:  98%|████████▊| 3991/4091 [00:38<00:00, 102.50it/s, loss=5.33, v_num=0]\u001b[A\n",
      "Epoch 0:  98%|████████▊| 4018/4091 [00:39<00:00, 102.90it/s, loss=5.33, v_num=0]\u001b[A\n",
      "Epoch 0:  99%|████████▉| 4045/4091 [00:39<00:00, 103.31it/s, loss=5.33, v_num=0]\u001b[A\n",
      "Epoch 0: 100%|████████▉| 4072/4091 [00:39<00:00, 103.71it/s, loss=5.33, v_num=0]\u001b[A\n",
      "Epoch 0: 100%|█| 4091/4091 [00:39<00:00, 103.74it/s, loss=5.33, v_num=0, loss/va\u001b[A\n",
      "Epoch 1:  90%|▉| 3687/4091 [00:37<00:04, 99.30it/s, loss=5.11, v_num=0, loss/val\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                       | 0/404 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  90%|▉| 3699/4091 [00:37<00:04, 97.92it/s, loss=5.11, v_num=0, loss/val\u001b[A\n",
      "Epoch 1:  91%|▉| 3726/4091 [00:37<00:03, 98.37it/s, loss=5.11, v_num=0, loss/val\u001b[A\n",
      "Epoch 1:  92%|▉| 3753/4091 [00:37<00:03, 98.79it/s, loss=5.11, v_num=0, loss/val\u001b[A\n",
      "Epoch 1:  92%|▉| 3780/4091 [00:38<00:03, 99.21it/s, loss=5.11, v_num=0, loss/val\u001b[A\n",
      "Validating:  23%|██████▋                      | 93/404 [00:00<00:02, 153.67it/s]\u001b[A\n",
      "Epoch 1:  93%|▉| 3807/4091 [00:38<00:02, 99.62it/s, loss=5.11, v_num=0, loss/val\u001b[A\n",
      "Epoch 1:  94%|▉| 3834/4091 [00:38<00:02, 100.04it/s, loss=5.11, v_num=0, loss/va\u001b[A\n",
      "Epoch 1:  94%|▉| 3861/4091 [00:38<00:02, 100.45it/s, loss=5.11, v_num=0, loss/va\u001b[A\n",
      "Epoch 1:  95%|▉| 3888/4091 [00:38<00:02, 100.86it/s, loss=5.11, v_num=0, loss/va\u001b[A\n",
      "Epoch 1:  96%|▉| 3915/4091 [00:38<00:01, 101.27it/s, loss=5.11, v_num=0, loss/va\u001b[A\n",
      "Epoch 1:  96%|▉| 3942/4091 [00:38<00:01, 101.67it/s, loss=5.11, v_num=0, loss/va\u001b[A\n",
      "Epoch 1:  97%|▉| 3969/4091 [00:38<00:01, 102.07it/s, loss=5.11, v_num=0, loss/va\u001b[A\n",
      "Epoch 1:  98%|▉| 3996/4091 [00:38<00:00, 102.48it/s, loss=5.11, v_num=0, loss/va\u001b[A\n",
      "Epoch 1:  98%|▉| 4023/4091 [00:39<00:00, 102.88it/s, loss=5.11, v_num=0, loss/va\u001b[A\n",
      "Epoch 1:  99%|▉| 4050/4091 [00:39<00:00, 103.28it/s, loss=5.11, v_num=0, loss/va\u001b[A\n",
      "Epoch 1: 100%|▉| 4077/4091 [00:39<00:00, 103.67it/s, loss=5.11, v_num=0, loss/va\u001b[A\n",
      "Epoch 1: 100%|█| 4091/4091 [00:39<00:00, 103.62it/s, loss=5.11, v_num=0, loss/va\u001b[A\n",
      "Epoch 2:  90%|▉| 3687/4091 [00:37<00:04, 98.03it/s, loss=4.93, v_num=0, loss/val\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                       | 0/404 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:  90%|▉| 3699/4091 [00:38<00:04, 96.75it/s, loss=4.93, v_num=0, loss/val\u001b[A\n",
      "Epoch 2:  91%|▉| 3726/4091 [00:38<00:03, 97.19it/s, loss=4.93, v_num=0, loss/val\u001b[A\n",
      "Epoch 2:  92%|▉| 3753/4091 [00:38<00:03, 97.60it/s, loss=4.93, v_num=0, loss/val\u001b[A\n",
      "Epoch 2:  92%|▉| 3780/4091 [00:38<00:03, 98.02it/s, loss=4.93, v_num=0, loss/val\u001b[A\n",
      "Epoch 2:  93%|▉| 3807/4091 [00:38<00:02, 98.44it/s, loss=4.93, v_num=0, loss/val\u001b[A\n",
      "Epoch 2:  94%|▉| 3834/4091 [00:38<00:02, 98.86it/s, loss=4.93, v_num=0, loss/val\u001b[A\n",
      "Epoch 2:  94%|▉| 3861/4091 [00:38<00:02, 99.27it/s, loss=4.93, v_num=0, loss/val\u001b[A\n",
      "Validating:  43%|████████████▏               | 175/404 [00:01<00:01, 212.21it/s]\u001b[A\n",
      "Epoch 2:  95%|▉| 3888/4091 [00:39<00:02, 99.68it/s, loss=4.93, v_num=0, loss/val\u001b[A\n",
      "Epoch 2:  96%|▉| 3915/4091 [00:39<00:01, 100.09it/s, loss=4.93, v_num=0, loss/va\u001b[A\n",
      "Epoch 2:  96%|▉| 3942/4091 [00:39<00:01, 100.49it/s, loss=4.93, v_num=0, loss/va\u001b[A\n",
      "Epoch 2:  97%|▉| 3969/4091 [00:39<00:01, 100.89it/s, loss=4.93, v_num=0, loss/va\u001b[A\n",
      "Epoch 2:  98%|▉| 3996/4091 [00:39<00:00, 101.30it/s, loss=4.93, v_num=0, loss/va\u001b[A\n",
      "Epoch 2:  98%|▉| 4023/4091 [00:39<00:00, 101.69it/s, loss=4.93, v_num=0, loss/va\u001b[A\n",
      "Epoch 2:  99%|▉| 4050/4091 [00:39<00:00, 102.09it/s, loss=4.93, v_num=0, loss/va\u001b[A\n",
      "Epoch 2: 100%|▉| 4077/4091 [00:39<00:00, 102.49it/s, loss=4.93, v_num=0, loss/va\u001b[A\n",
      "Epoch 2: 100%|█| 4091/4091 [00:39<00:00, 102.45it/s, loss=4.93, v_num=0, loss/va\u001b[A\n",
      "Epoch 3:  90%|▉| 3687/4091 [00:37<00:04, 98.17it/s, loss=4.8, v_num=0, loss/vali\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                       | 0/404 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:  90%|▉| 3699/4091 [00:38<00:04, 96.92it/s, loss=4.8, v_num=0, loss/vali\u001b[A\n",
      "Epoch 3:  91%|▉| 3726/4091 [00:38<00:03, 97.37it/s, loss=4.8, v_num=0, loss/vali\u001b[A\n",
      "Epoch 3:  92%|▉| 3753/4091 [00:38<00:03, 97.79it/s, loss=4.8, v_num=0, loss/vali\u001b[A\n",
      "Epoch 3:  92%|▉| 3780/4091 [00:38<00:03, 98.21it/s, loss=4.8, v_num=0, loss/vali\u001b[A\n",
      "Epoch 3:  93%|▉| 3807/4091 [00:38<00:02, 98.63it/s, loss=4.8, v_num=0, loss/vali\u001b[A\n",
      "Epoch 3:  94%|▉| 3834/4091 [00:38<00:02, 99.05it/s, loss=4.8, v_num=0, loss/vali\u001b[A\n",
      "Epoch 3:  94%|▉| 3861/4091 [00:38<00:02, 99.46it/s, loss=4.8, v_num=0, loss/vali\u001b[A\n",
      "Validating:  43%|████████████▏               | 175/404 [00:01<00:01, 212.88it/s]\u001b[A\n",
      "Epoch 3:  95%|▉| 3888/4091 [00:38<00:02, 99.87it/s, loss=4.8, v_num=0, loss/vali\u001b[A\n",
      "Epoch 3:  96%|▉| 3915/4091 [00:39<00:01, 100.28it/s, loss=4.8, v_num=0, loss/val\u001b[A\n",
      "Epoch 3:  96%|▉| 3942/4091 [00:39<00:01, 100.69it/s, loss=4.8, v_num=0, loss/val\u001b[A\n",
      "Epoch 3:  97%|▉| 3969/4091 [00:39<00:01, 101.09it/s, loss=4.8, v_num=0, loss/val\u001b[A\n",
      "Epoch 3:  98%|▉| 3996/4091 [00:39<00:00, 101.49it/s, loss=4.8, v_num=0, loss/val\u001b[A\n",
      "Epoch 3:  98%|▉| 4023/4091 [00:39<00:00, 101.89it/s, loss=4.8, v_num=0, loss/val\u001b[A\n",
      "Epoch 3:  99%|▉| 4050/4091 [00:39<00:00, 102.29it/s, loss=4.8, v_num=0, loss/val\u001b[A\n",
      "Epoch 3: 100%|▉| 4077/4091 [00:39<00:00, 102.69it/s, loss=4.8, v_num=0, loss/val\u001b[A\n",
      "Epoch 3: 100%|█| 4091/4091 [00:39<00:00, 102.65it/s, loss=4.8, v_num=0, loss/val\u001b[A\n",
      "Epoch 4:  90%|▉| 3687/4091 [00:37<00:04, 98.16it/s, loss=4.79, v_num=0, loss/val\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                       | 0/404 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4:  90%|▉| 3699/4091 [00:38<00:04, 96.90it/s, loss=4.79, v_num=0, loss/val\u001b[A\n",
      "Epoch 4:  91%|▉| 3726/4091 [00:38<00:03, 97.34it/s, loss=4.79, v_num=0, loss/val\u001b[A\n",
      "Epoch 4:  92%|▉| 3753/4091 [00:38<00:03, 97.75it/s, loss=4.79, v_num=0, loss/val\u001b[A\n",
      "Epoch 4:  92%|▉| 3780/4091 [00:38<00:03, 98.17it/s, loss=4.79, v_num=0, loss/val\u001b[A\n",
      "Epoch 4:  93%|▉| 3807/4091 [00:38<00:02, 98.59it/s, loss=4.79, v_num=0, loss/val\u001b[A\n",
      "Epoch 4:  94%|▉| 3834/4091 [00:38<00:02, 99.00it/s, loss=4.79, v_num=0, loss/val\u001b[A\n",
      "Epoch 4:  94%|▉| 3861/4091 [00:38<00:02, 99.41it/s, loss=4.79, v_num=0, loss/val\u001b[A\n",
      "Validating:  43%|████████████                | 174/404 [00:01<00:01, 211.09it/s]\u001b[A\n",
      "Epoch 4:  95%|▉| 3888/4091 [00:38<00:02, 99.82it/s, loss=4.79, v_num=0, loss/val\u001b[A\n",
      "Epoch 4:  96%|▉| 3915/4091 [00:39<00:01, 100.22it/s, loss=4.79, v_num=0, loss/va\u001b[A\n",
      "Epoch 4:  96%|▉| 3942/4091 [00:39<00:01, 100.62it/s, loss=4.79, v_num=0, loss/va\u001b[A\n",
      "Epoch 4:  97%|▉| 3969/4091 [00:39<00:01, 101.03it/s, loss=4.79, v_num=0, loss/va\u001b[A\n",
      "Epoch 4:  98%|▉| 3996/4091 [00:39<00:00, 101.43it/s, loss=4.79, v_num=0, loss/va\u001b[A\n",
      "Epoch 4:  98%|▉| 4023/4091 [00:39<00:00, 101.82it/s, loss=4.79, v_num=0, loss/va\u001b[A\n",
      "Epoch 4:  99%|▉| 4050/4091 [00:39<00:00, 102.20it/s, loss=4.79, v_num=0, loss/va\u001b[A\n",
      "Epoch 4: 100%|▉| 4077/4091 [00:39<00:00, 102.58it/s, loss=4.79, v_num=0, loss/va\u001b[A\n",
      "Epoch 4: 100%|█| 4091/4091 [00:39<00:00, 102.55it/s, loss=4.79, v_num=0, loss/va\u001b[A\n",
      "Epoch 5:  90%|▉| 3687/4091 [00:37<00:04, 98.56it/s, loss=4.7, v_num=0, loss/vali\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                       | 0/404 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5:  90%|▉| 3699/4091 [00:38<00:04, 97.29it/s, loss=4.7, v_num=0, loss/vali\u001b[A\n",
      "Epoch 5:  91%|▉| 3726/4091 [00:38<00:03, 97.72it/s, loss=4.7, v_num=0, loss/vali\u001b[A\n",
      "Epoch 5:  92%|▉| 3753/4091 [00:38<00:03, 98.14it/s, loss=4.7, v_num=0, loss/vali\u001b[A\n",
      "Epoch 5:  92%|▉| 3780/4091 [00:38<00:03, 98.56it/s, loss=4.7, v_num=0, loss/vali\u001b[A\n",
      "Epoch 5:  93%|▉| 3807/4091 [00:38<00:02, 98.98it/s, loss=4.7, v_num=0, loss/vali\u001b[A\n",
      "Epoch 5:  94%|▉| 3834/4091 [00:38<00:02, 99.39it/s, loss=4.7, v_num=0, loss/vali\u001b[A\n",
      "Epoch 5:  94%|▉| 3861/4091 [00:38<00:02, 99.80it/s, loss=4.7, v_num=0, loss/vali\u001b[A\n",
      "Epoch 5:  95%|▉| 3888/4091 [00:38<00:02, 100.22it/s, loss=4.7, v_num=0, loss/val\u001b[A\n",
      "Validating:  50%|█████████████▉              | 201/404 [00:01<00:00, 220.70it/s]\u001b[A\n",
      "Epoch 5:  96%|▉| 3915/4091 [00:38<00:01, 100.62it/s, loss=4.7, v_num=0, loss/val\u001b[A\n",
      "Epoch 5:  96%|▉| 3942/4091 [00:39<00:01, 101.03it/s, loss=4.7, v_num=0, loss/val\u001b[A\n",
      "Epoch 5:  97%|▉| 3969/4091 [00:39<00:01, 101.43it/s, loss=4.7, v_num=0, loss/val\u001b[A\n",
      "Epoch 5:  98%|▉| 3996/4091 [00:39<00:00, 101.83it/s, loss=4.7, v_num=0, loss/val\u001b[A\n",
      "Epoch 5:  98%|▉| 4023/4091 [00:39<00:00, 102.23it/s, loss=4.7, v_num=0, loss/val\u001b[A\n",
      "Epoch 5:  99%|▉| 4050/4091 [00:39<00:00, 102.63it/s, loss=4.7, v_num=0, loss/val\u001b[A\n",
      "Epoch 5: 100%|▉| 4077/4091 [00:39<00:00, 103.02it/s, loss=4.7, v_num=0, loss/val\u001b[A\n",
      "Epoch 5: 100%|█| 4091/4091 [00:39<00:00, 103.00it/s, loss=4.7, v_num=0, loss/val\u001b[A\n",
      "Epoch 6:  90%|▉| 3687/4091 [00:37<00:04, 98.61it/s, loss=4.64, v_num=0, loss/val\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                       | 0/404 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 6:  90%|▉| 3699/4091 [00:38<00:04, 97.33it/s, loss=4.64, v_num=0, loss/val\u001b[A\n",
      "Epoch 6:  91%|▉| 3726/4091 [00:38<00:03, 97.76it/s, loss=4.64, v_num=0, loss/val\u001b[A\n",
      "Epoch 6:  92%|▉| 3753/4091 [00:38<00:03, 98.18it/s, loss=4.64, v_num=0, loss/val\u001b[A\n",
      "Epoch 6:  92%|▉| 3780/4091 [00:38<00:03, 98.60it/s, loss=4.64, v_num=0, loss/val\u001b[A\n",
      "Epoch 6:  93%|▉| 3807/4091 [00:38<00:02, 99.02it/s, loss=4.64, v_num=0, loss/val\u001b[A\n",
      "Epoch 6:  94%|▉| 3834/4091 [00:38<00:02, 99.43it/s, loss=4.64, v_num=0, loss/val\u001b[A\n",
      "Epoch 6:  94%|▉| 3861/4091 [00:38<00:02, 99.84it/s, loss=4.64, v_num=0, loss/val\u001b[A\n",
      "Validating:  43%|████████████▏               | 175/404 [00:01<00:01, 210.74it/s]\u001b[A\n",
      "Epoch 6:  95%|▉| 3888/4091 [00:38<00:02, 100.24it/s, loss=4.64, v_num=0, loss/va\u001b[A\n",
      "Epoch 6:  96%|▉| 3915/4091 [00:38<00:01, 100.64it/s, loss=4.64, v_num=0, loss/va\u001b[A\n",
      "Epoch 6:  96%|▉| 3942/4091 [00:39<00:01, 101.05it/s, loss=4.64, v_num=0, loss/va\u001b[A\n",
      "Epoch 6:  97%|▉| 3969/4091 [00:39<00:01, 101.45it/s, loss=4.64, v_num=0, loss/va\u001b[A\n",
      "Epoch 6:  98%|▉| 3996/4091 [00:39<00:00, 101.86it/s, loss=4.64, v_num=0, loss/va\u001b[A\n",
      "Epoch 6:  98%|▉| 4023/4091 [00:39<00:00, 102.26it/s, loss=4.64, v_num=0, loss/va\u001b[A\n",
      "Epoch 6:  99%|▉| 4050/4091 [00:39<00:00, 102.66it/s, loss=4.64, v_num=0, loss/va\u001b[A\n",
      "Epoch 6: 100%|▉| 4077/4091 [00:39<00:00, 103.06it/s, loss=4.64, v_num=0, loss/va\u001b[A\n",
      "Epoch 6: 100%|█| 4091/4091 [00:39<00:00, 103.05it/s, loss=4.64, v_num=0, loss/va\u001b[A\n",
      "Epoch 7:  90%|▉| 3687/4091 [00:37<00:04, 98.58it/s, loss=4.6, v_num=0, loss/vali\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                       | 0/404 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 7:  90%|▉| 3699/4091 [00:38<00:04, 97.31it/s, loss=4.6, v_num=0, loss/vali\u001b[A\n",
      "Epoch 7:  91%|▉| 3726/4091 [00:38<00:03, 97.74it/s, loss=4.6, v_num=0, loss/vali\u001b[A\n",
      "Epoch 7:  92%|▉| 3753/4091 [00:38<00:03, 98.16it/s, loss=4.6, v_num=0, loss/vali\u001b[A\n",
      "Epoch 7:  92%|▉| 3780/4091 [00:38<00:03, 98.58it/s, loss=4.6, v_num=0, loss/vali\u001b[A\n",
      "Epoch 7:  93%|▉| 3807/4091 [00:38<00:02, 99.00it/s, loss=4.6, v_num=0, loss/vali\u001b[A\n",
      "Epoch 7:  94%|▉| 3834/4091 [00:38<00:02, 99.42it/s, loss=4.6, v_num=0, loss/vali\u001b[A\n",
      "Epoch 7:  94%|▉| 3861/4091 [00:38<00:02, 99.83it/s, loss=4.6, v_num=0, loss/vali\u001b[A\n",
      "Validating:  43%|████████████                | 174/404 [00:01<00:01, 211.04it/s]\u001b[A\n",
      "Epoch 7:  95%|▉| 3888/4091 [00:38<00:02, 100.23it/s, loss=4.6, v_num=0, loss/val\u001b[A\n",
      "Epoch 7:  96%|▉| 3915/4091 [00:38<00:01, 100.64it/s, loss=4.6, v_num=0, loss/val\u001b[A\n",
      "Epoch 7:  96%|▉| 3942/4091 [00:39<00:01, 101.04it/s, loss=4.6, v_num=0, loss/val\u001b[A\n",
      "Epoch 7:  97%|▉| 3969/4091 [00:39<00:01, 101.44it/s, loss=4.6, v_num=0, loss/val\u001b[A\n",
      "Epoch 7:  98%|▉| 3996/4091 [00:39<00:00, 101.84it/s, loss=4.6, v_num=0, loss/val\u001b[A\n",
      "Epoch 7:  98%|▉| 4023/4091 [00:39<00:00, 102.24it/s, loss=4.6, v_num=0, loss/val\u001b[A\n",
      "Epoch 7:  99%|▉| 4050/4091 [00:39<00:00, 102.63it/s, loss=4.6, v_num=0, loss/val\u001b[A\n",
      "Epoch 7: 100%|▉| 4077/4091 [00:39<00:00, 103.03it/s, loss=4.6, v_num=0, loss/val\u001b[A\n",
      "Epoch 7: 100%|█| 4091/4091 [00:39<00:00, 103.00it/s, loss=4.6, v_num=0, loss/val\u001b[A\n",
      "Epoch 8:  90%|▉| 3687/4091 [00:37<00:04, 99.07it/s, loss=4.55, v_num=0, loss/val\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                       | 0/404 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 8:  90%|▉| 3699/4091 [00:37<00:04, 97.79it/s, loss=4.55, v_num=0, loss/val\u001b[A\n",
      "Epoch 8:  91%|▉| 3726/4091 [00:37<00:03, 98.22it/s, loss=4.55, v_num=0, loss/val\u001b[A\n",
      "Epoch 8:  92%|▉| 3753/4091 [00:38<00:03, 98.64it/s, loss=4.55, v_num=0, loss/val\u001b[A\n",
      "Epoch 8:  92%|▉| 3780/4091 [00:38<00:03, 99.06it/s, loss=4.55, v_num=0, loss/val\u001b[A\n",
      "Epoch 8:  93%|▉| 3807/4091 [00:38<00:02, 99.47it/s, loss=4.55, v_num=0, loss/val\u001b[A\n",
      "Epoch 8:  94%|▉| 3834/4091 [00:38<00:02, 99.88it/s, loss=4.55, v_num=0, loss/val\u001b[A\n",
      "Epoch 8:  94%|▉| 3861/4091 [00:38<00:02, 100.30it/s, loss=4.55, v_num=0, loss/va\u001b[A\n",
      "Validating:  43%|████████████                | 174/404 [00:01<00:01, 210.27it/s]\u001b[A\n",
      "Epoch 8:  95%|▉| 3888/4091 [00:38<00:02, 100.70it/s, loss=4.55, v_num=0, loss/va\u001b[A\n",
      "Epoch 8:  96%|▉| 3915/4091 [00:38<00:01, 101.11it/s, loss=4.55, v_num=0, loss/va\u001b[A\n",
      "Epoch 8:  96%|▉| 3942/4091 [00:38<00:01, 101.52it/s, loss=4.55, v_num=0, loss/va\u001b[A\n",
      "Epoch 8:  97%|▉| 3969/4091 [00:38<00:01, 101.92it/s, loss=4.55, v_num=0, loss/va\u001b[A\n",
      "Epoch 8:  98%|▉| 3996/4091 [00:39<00:00, 102.33it/s, loss=4.55, v_num=0, loss/va\u001b[A\n",
      "Epoch 8:  98%|▉| 4023/4091 [00:39<00:00, 102.73it/s, loss=4.55, v_num=0, loss/va\u001b[A\n",
      "Epoch 8:  99%|▉| 4050/4091 [00:39<00:00, 103.12it/s, loss=4.55, v_num=0, loss/va\u001b[A\n",
      "Epoch 8: 100%|▉| 4077/4091 [00:39<00:00, 103.52it/s, loss=4.55, v_num=0, loss/va\u001b[A\n",
      "Epoch 8: 100%|█| 4091/4091 [00:39<00:00, 103.49it/s, loss=4.55, v_num=0, loss/va\u001b[A\n",
      "Epoch 9:  90%|▉| 3687/4091 [00:37<00:04, 98.81it/s, loss=4.54, v_num=0, loss/val\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                       | 0/404 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 9:  90%|▉| 3699/4091 [00:37<00:04, 97.52it/s, loss=4.54, v_num=0, loss/val\u001b[A\n",
      "Epoch 9:  91%|▉| 3726/4091 [00:38<00:03, 97.95it/s, loss=4.54, v_num=0, loss/val\u001b[A\n",
      "Epoch 9:  92%|▉| 3753/4091 [00:38<00:03, 98.37it/s, loss=4.54, v_num=0, loss/val\u001b[A\n",
      "Epoch 9:  92%|▉| 3780/4091 [00:38<00:03, 98.80it/s, loss=4.54, v_num=0, loss/val\u001b[A\n",
      "Epoch 9:  93%|▉| 3807/4091 [00:38<00:02, 99.22it/s, loss=4.54, v_num=0, loss/val\u001b[A\n",
      "Epoch 9:  94%|▉| 3834/4091 [00:38<00:02, 99.61it/s, loss=4.54, v_num=0, loss/val\u001b[A\n",
      "Epoch 9:  94%|▉| 3861/4091 [00:38<00:02, 100.02it/s, loss=4.54, v_num=0, loss/va\u001b[A\n",
      "Validating:  43%|████████████                | 174/404 [00:01<00:01, 208.43it/s]\u001b[A\n",
      "Epoch 9:  95%|▉| 3888/4091 [00:38<00:02, 100.42it/s, loss=4.54, v_num=0, loss/va\u001b[A\n",
      "Epoch 9:  96%|▉| 3915/4091 [00:38<00:01, 100.83it/s, loss=4.54, v_num=0, loss/va\u001b[A\n",
      "Epoch 9:  96%|▉| 3942/4091 [00:38<00:01, 101.24it/s, loss=4.54, v_num=0, loss/va\u001b[A\n",
      "Epoch 9:  97%|▉| 3969/4091 [00:39<00:01, 101.64it/s, loss=4.54, v_num=0, loss/va\u001b[A\n",
      "Epoch 9:  98%|▉| 3996/4091 [00:39<00:00, 102.04it/s, loss=4.54, v_num=0, loss/va\u001b[A\n",
      "Epoch 9:  98%|▉| 4023/4091 [00:39<00:00, 102.43it/s, loss=4.54, v_num=0, loss/va\u001b[A\n",
      "Epoch 9:  99%|▉| 4050/4091 [00:39<00:00, 102.82it/s, loss=4.54, v_num=0, loss/va\u001b[A\n",
      "Epoch 9: 100%|▉| 4077/4091 [00:39<00:00, 103.22it/s, loss=4.54, v_num=0, loss/va\u001b[A\n",
      "Epoch 9: 100%|█| 4091/4091 [00:39<00:00, 103.17it/s, loss=4.54, v_num=0, loss/va\u001b[A\n",
      "Epoch 10:  90%|▉| 3687/4091 [00:37<00:04, 98.23it/s, loss=4.53, v_num=0, loss/va\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                       | 0/404 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 10:  90%|▉| 3699/4091 [00:38<00:04, 96.96it/s, loss=4.53, v_num=0, loss/va\u001b[A\n",
      "Epoch 10:  91%|▉| 3726/4091 [00:38<00:03, 97.39it/s, loss=4.53, v_num=0, loss/va\u001b[A\n",
      "Epoch 10:  92%|▉| 3753/4091 [00:38<00:03, 97.81it/s, loss=4.53, v_num=0, loss/va\u001b[A\n",
      "Epoch 10:  92%|▉| 3780/4091 [00:38<00:03, 98.23it/s, loss=4.53, v_num=0, loss/va\u001b[A\n",
      "Epoch 10:  93%|▉| 3807/4091 [00:38<00:02, 98.65it/s, loss=4.53, v_num=0, loss/va\u001b[A\n",
      "Epoch 10:  94%|▉| 3834/4091 [00:38<00:02, 99.06it/s, loss=4.53, v_num=0, loss/va\u001b[A\n",
      "Epoch 10:  94%|▉| 3861/4091 [00:38<00:02, 99.47it/s, loss=4.53, v_num=0, loss/va\u001b[A\n",
      "Epoch 10:  95%|▉| 3888/4091 [00:38<00:02, 99.88it/s, loss=4.53, v_num=0, loss/va\u001b[A\n",
      "Validating:  50%|█████████████▉              | 201/404 [00:01<00:00, 220.66it/s]\u001b[A\n",
      "Epoch 10:  96%|▉| 3915/4091 [00:39<00:01, 100.28it/s, loss=4.53, v_num=0, loss/v\u001b[A\n",
      "Epoch 10:  96%|▉| 3942/4091 [00:39<00:01, 100.69it/s, loss=4.53, v_num=0, loss/v\u001b[A\n",
      "Epoch 10:  97%|▉| 3969/4091 [00:39<00:01, 101.09it/s, loss=4.53, v_num=0, loss/v\u001b[A\n",
      "Epoch 10:  98%|▉| 3996/4091 [00:39<00:00, 101.49it/s, loss=4.53, v_num=0, loss/v\u001b[A\n",
      "Epoch 10:  98%|▉| 4023/4091 [00:39<00:00, 101.89it/s, loss=4.53, v_num=0, loss/v\u001b[A\n",
      "Epoch 10:  99%|▉| 4050/4091 [00:39<00:00, 102.29it/s, loss=4.53, v_num=0, loss/v\u001b[A\n",
      "Epoch 10: 100%|▉| 4077/4091 [00:39<00:00, 102.68it/s, loss=4.53, v_num=0, loss/v\u001b[A\n",
      "Epoch 10: 100%|█| 4091/4091 [00:39<00:00, 102.66it/s, loss=4.53, v_num=0, loss/v\u001b[A\n",
      "Epoch 11:  90%|▉| 3687/4091 [00:37<00:04, 98.02it/s, loss=4.46, v_num=0, loss/va\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                       | 0/404 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 11:  90%|▉| 3699/4091 [00:38<00:04, 96.78it/s, loss=4.46, v_num=0, loss/va\u001b[A\n",
      "Epoch 11:  91%|▉| 3726/4091 [00:38<00:03, 97.20it/s, loss=4.46, v_num=0, loss/va\u001b[A\n",
      "Epoch 11:  92%|▉| 3753/4091 [00:38<00:03, 97.62it/s, loss=4.46, v_num=0, loss/va\u001b[A\n",
      "Epoch 11:  92%|▉| 3780/4091 [00:38<00:03, 98.04it/s, loss=4.46, v_num=0, loss/va\u001b[A\n",
      "Epoch 11:  93%|▉| 3807/4091 [00:38<00:02, 98.45it/s, loss=4.46, v_num=0, loss/va\u001b[A\n",
      "Epoch 11:  94%|▉| 3834/4091 [00:38<00:02, 98.86it/s, loss=4.46, v_num=0, loss/va\u001b[A\n",
      "Validating:  37%|██████████▎                 | 148/404 [00:01<00:01, 196.84it/s]\u001b[A\n",
      "Epoch 11:  94%|▉| 3861/4091 [00:38<00:02, 99.27it/s, loss=4.46, v_num=0, loss/va\u001b[A\n",
      "Epoch 11:  95%|▉| 3888/4091 [00:39<00:02, 99.68it/s, loss=4.46, v_num=0, loss/va\u001b[A\n",
      "Epoch 11:  96%|▉| 3915/4091 [00:39<00:01, 100.08it/s, loss=4.46, v_num=0, loss/v\u001b[A\n",
      "Epoch 11:  96%|▉| 3942/4091 [00:39<00:01, 100.49it/s, loss=4.46, v_num=0, loss/v\u001b[A\n",
      "Epoch 11:  97%|▉| 3969/4091 [00:39<00:01, 100.89it/s, loss=4.46, v_num=0, loss/v\u001b[A\n",
      "Epoch 11:  98%|▉| 3996/4091 [00:39<00:00, 101.29it/s, loss=4.46, v_num=0, loss/v\u001b[A\n",
      "Epoch 11:  98%|▉| 4023/4091 [00:39<00:00, 101.69it/s, loss=4.46, v_num=0, loss/v\u001b[A\n",
      "Epoch 11:  99%|▉| 4050/4091 [00:39<00:00, 102.08it/s, loss=4.46, v_num=0, loss/v\u001b[A\n",
      "Epoch 11: 100%|▉| 4077/4091 [00:39<00:00, 102.48it/s, loss=4.46, v_num=0, loss/v\u001b[A\n",
      "Epoch 11: 100%|█| 4091/4091 [00:39<00:00, 102.47it/s, loss=4.46, v_num=0, loss/v\u001b[A\n",
      "Epoch 12:  90%|▉| 3687/4091 [00:37<00:04, 98.38it/s, loss=4.44, v_num=0, loss/va\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                       | 0/404 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 12:  90%|▉| 3699/4091 [00:38<00:04, 97.12it/s, loss=4.44, v_num=0, loss/va\u001b[A\n",
      "Epoch 12:  91%|▉| 3726/4091 [00:38<00:03, 97.56it/s, loss=4.44, v_num=0, loss/va\u001b[A\n",
      "Epoch 12:  92%|▉| 3753/4091 [00:38<00:03, 97.98it/s, loss=4.44, v_num=0, loss/va\u001b[A\n",
      "Epoch 12:  92%|▉| 3780/4091 [00:38<00:03, 98.40it/s, loss=4.44, v_num=0, loss/va\u001b[A\n",
      "Epoch 12:  93%|▉| 3807/4091 [00:38<00:02, 98.82it/s, loss=4.44, v_num=0, loss/va\u001b[A\n",
      "Epoch 12:  94%|▉| 3834/4091 [00:38<00:02, 99.23it/s, loss=4.44, v_num=0, loss/va\u001b[A\n",
      "Epoch 12:  94%|▉| 3861/4091 [00:38<00:02, 99.65it/s, loss=4.44, v_num=0, loss/va\u001b[A\n",
      "Epoch 12:  95%|▉| 3888/4091 [00:38<00:02, 100.06it/s, loss=4.44, v_num=0, loss/v\u001b[A\n",
      "Validating:  50%|█████████████▉              | 201/404 [00:01<00:00, 221.39it/s]\u001b[A\n",
      "Epoch 12:  96%|▉| 3915/4091 [00:38<00:01, 100.46it/s, loss=4.44, v_num=0, loss/v\u001b[A\n",
      "Epoch 12:  96%|▉| 3942/4091 [00:39<00:01, 100.87it/s, loss=4.44, v_num=0, loss/v\u001b[A\n",
      "Epoch 12:  97%|▉| 3969/4091 [00:39<00:01, 101.27it/s, loss=4.44, v_num=0, loss/v\u001b[A\n",
      "Epoch 12:  98%|▉| 3996/4091 [00:39<00:00, 101.68it/s, loss=4.44, v_num=0, loss/v\u001b[A\n",
      "Epoch 12:  98%|▉| 4023/4091 [00:39<00:00, 102.08it/s, loss=4.44, v_num=0, loss/v\u001b[A\n",
      "Epoch 12:  99%|▉| 4050/4091 [00:39<00:00, 102.47it/s, loss=4.44, v_num=0, loss/v\u001b[A\n",
      "Epoch 12: 100%|▉| 4077/4091 [00:39<00:00, 102.87it/s, loss=4.44, v_num=0, loss/v\u001b[A\n",
      "Epoch 12: 100%|█| 4091/4091 [00:39<00:00, 102.83it/s, loss=4.44, v_num=0, loss/v\u001b[A\n",
      "Epoch 13:  90%|▉| 3687/4091 [00:37<00:04, 98.29it/s, loss=4.39, v_num=0, loss/va\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                       | 0/404 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 13:  90%|▉| 3699/4091 [00:38<00:04, 97.00it/s, loss=4.39, v_num=0, loss/va\u001b[A\n",
      "Epoch 13:  91%|▉| 3726/4091 [00:38<00:03, 97.44it/s, loss=4.39, v_num=0, loss/va\u001b[A\n",
      "Epoch 13:  92%|▉| 3753/4091 [00:38<00:03, 97.86it/s, loss=4.39, v_num=0, loss/va\u001b[A\n",
      "Epoch 13:  92%|▉| 3780/4091 [00:38<00:03, 98.27it/s, loss=4.39, v_num=0, loss/va\u001b[A\n",
      "Epoch 13:  93%|▉| 3807/4091 [00:38<00:02, 98.68it/s, loss=4.39, v_num=0, loss/va\u001b[A\n",
      "Validating:  30%|████████▍                   | 121/404 [00:01<00:01, 178.23it/s]\u001b[A\n",
      "Epoch 13:  94%|▉| 3834/4091 [00:38<00:02, 99.08it/s, loss=4.39, v_num=0, loss/va\u001b[A\n",
      "Epoch 13:  94%|▉| 3861/4091 [00:38<00:02, 99.49it/s, loss=4.39, v_num=0, loss/va\u001b[A\n",
      "Epoch 13:  95%|▉| 3888/4091 [00:38<00:02, 99.90it/s, loss=4.39, v_num=0, loss/va\u001b[A\n",
      "Epoch 13:  96%|▉| 3915/4091 [00:39<00:01, 100.30it/s, loss=4.39, v_num=0, loss/v\u001b[A\n",
      "Epoch 13:  96%|▉| 3942/4091 [00:39<00:01, 100.71it/s, loss=4.39, v_num=0, loss/v\u001b[A\n",
      "Epoch 13:  97%|▉| 3969/4091 [00:39<00:01, 101.11it/s, loss=4.39, v_num=0, loss/v\u001b[A\n",
      "Epoch 13:  98%|▉| 3996/4091 [00:39<00:00, 101.50it/s, loss=4.39, v_num=0, loss/v\u001b[A\n",
      "Epoch 13:  98%|▉| 4023/4091 [00:39<00:00, 101.89it/s, loss=4.39, v_num=0, loss/v\u001b[A\n",
      "Epoch 13:  99%|▉| 4050/4091 [00:39<00:00, 102.28it/s, loss=4.39, v_num=0, loss/v\u001b[A\n",
      "Epoch 13: 100%|▉| 4077/4091 [00:39<00:00, 102.68it/s, loss=4.39, v_num=0, loss/v\u001b[A\n",
      "Epoch 13: 100%|█| 4091/4091 [00:39<00:00, 102.65it/s, loss=4.39, v_num=0, loss/v\u001b[A\n",
      "Epoch 14:  90%|▉| 3687/4091 [00:38<00:04, 96.89it/s, loss=4.33, v_num=0, loss/va\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                       | 0/404 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 14:  90%|▉| 3699/4091 [00:38<00:04, 95.66it/s, loss=4.33, v_num=0, loss/va\u001b[A\n",
      "Epoch 14:  91%|▉| 3726/4091 [00:38<00:03, 96.11it/s, loss=4.33, v_num=0, loss/va\u001b[A\n",
      "Epoch 14:  92%|▉| 3753/4091 [00:38<00:03, 96.53it/s, loss=4.33, v_num=0, loss/va\u001b[A\n",
      "Epoch 14:  92%|▉| 3780/4091 [00:38<00:03, 96.95it/s, loss=4.33, v_num=0, loss/va\u001b[A\n",
      "Epoch 14:  93%|▉| 3807/4091 [00:39<00:02, 97.36it/s, loss=4.33, v_num=0, loss/va\u001b[A\n",
      "Epoch 14:  94%|▉| 3834/4091 [00:39<00:02, 97.77it/s, loss=4.33, v_num=0, loss/va\u001b[A\n",
      "Epoch 14:  94%|▉| 3861/4091 [00:39<00:02, 98.18it/s, loss=4.33, v_num=0, loss/va\u001b[A\n",
      "Validating:  43%|████████████                | 174/404 [00:01<00:01, 210.30it/s]\u001b[A\n",
      "Epoch 14:  95%|▉| 3888/4091 [00:39<00:02, 98.59it/s, loss=4.33, v_num=0, loss/va\u001b[A\n",
      "Epoch 14:  96%|▉| 3915/4091 [00:39<00:01, 98.99it/s, loss=4.33, v_num=0, loss/va\u001b[A\n",
      "Epoch 14:  96%|▉| 3942/4091 [00:39<00:01, 99.40it/s, loss=4.33, v_num=0, loss/va\u001b[A\n",
      "Epoch 14:  97%|▉| 3969/4091 [00:39<00:01, 99.80it/s, loss=4.33, v_num=0, loss/va\u001b[A\n",
      "Epoch 14:  98%|▉| 3996/4091 [00:39<00:00, 100.20it/s, loss=4.33, v_num=0, loss/v\u001b[A\n",
      "Epoch 14:  98%|▉| 4023/4091 [00:39<00:00, 100.60it/s, loss=4.33, v_num=0, loss/v\u001b[A\n",
      "Epoch 14:  99%|▉| 4050/4091 [00:40<00:00, 101.00it/s, loss=4.33, v_num=0, loss/v\u001b[A\n",
      "Epoch 14: 100%|▉| 4077/4091 [00:40<00:00, 101.39it/s, loss=4.33, v_num=0, loss/v\u001b[A\n",
      "Epoch 14: 100%|█| 4091/4091 [00:40<00:00, 101.36it/s, loss=4.33, v_num=0, loss/v\u001b[A\n",
      "Epoch 15:  90%|▉| 3687/4091 [00:37<00:04, 98.51it/s, loss=4.4, v_num=0, loss/val\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                       | 0/404 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 15:  90%|▉| 3699/4091 [00:38<00:04, 97.23it/s, loss=4.4, v_num=0, loss/val\u001b[A\n",
      "Epoch 15:  91%|▉| 3726/4091 [00:38<00:03, 97.68it/s, loss=4.4, v_num=0, loss/val\u001b[A\n",
      "Epoch 15:  92%|▉| 3753/4091 [00:38<00:03, 98.10it/s, loss=4.4, v_num=0, loss/val\u001b[A\n",
      "Epoch 15:  92%|▉| 3780/4091 [00:38<00:03, 98.52it/s, loss=4.4, v_num=0, loss/val\u001b[A\n",
      "Epoch 15:  93%|▉| 3807/4091 [00:38<00:02, 98.94it/s, loss=4.4, v_num=0, loss/val\u001b[A\n",
      "Epoch 15:  94%|▉| 3834/4091 [00:38<00:02, 99.35it/s, loss=4.4, v_num=0, loss/val\u001b[A\n",
      "Epoch 15:  94%|▉| 3861/4091 [00:38<00:02, 99.77it/s, loss=4.4, v_num=0, loss/val\u001b[A\n",
      "Validating:  43%|████████████▏               | 175/404 [00:01<00:01, 212.77it/s]\u001b[A\n",
      "Epoch 15:  95%|▉| 3888/4091 [00:38<00:02, 100.17it/s, loss=4.4, v_num=0, loss/va\u001b[A\n",
      "Epoch 15:  96%|▉| 3915/4091 [00:38<00:01, 100.58it/s, loss=4.4, v_num=0, loss/va\u001b[A\n",
      "Epoch 15:  96%|▉| 3942/4091 [00:39<00:01, 100.99it/s, loss=4.4, v_num=0, loss/va\u001b[A\n",
      "Epoch 15:  97%|▉| 3969/4091 [00:39<00:01, 101.38it/s, loss=4.4, v_num=0, loss/va\u001b[A\n",
      "Epoch 15:  98%|▉| 3996/4091 [00:39<00:00, 101.79it/s, loss=4.4, v_num=0, loss/va\u001b[A\n",
      "Epoch 15:  98%|▉| 4023/4091 [00:39<00:00, 102.18it/s, loss=4.4, v_num=0, loss/va\u001b[A\n",
      "Epoch 15:  99%|▉| 4050/4091 [00:39<00:00, 102.58it/s, loss=4.4, v_num=0, loss/va\u001b[A\n",
      "Epoch 15: 100%|▉| 4077/4091 [00:39<00:00, 102.98it/s, loss=4.4, v_num=0, loss/va\u001b[A\n",
      "Epoch 15: 100%|█| 4091/4091 [00:39<00:00, 102.94it/s, loss=4.4, v_num=0, loss/va\u001b[A\n",
      "Epoch 16:  90%|▉| 3687/4091 [00:38<00:04, 96.74it/s, loss=4.32, v_num=0, loss/va\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                       | 0/404 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 16:  90%|▉| 3699/4091 [00:38<00:04, 95.55it/s, loss=4.32, v_num=0, loss/va\u001b[A\n",
      "Epoch 16:  91%|▉| 3726/4091 [00:38<00:03, 95.98it/s, loss=4.32, v_num=0, loss/va\u001b[A\n",
      "Epoch 16:  92%|▉| 3753/4091 [00:38<00:03, 96.40it/s, loss=4.32, v_num=0, loss/va\u001b[A\n",
      "Epoch 16:  92%|▉| 3780/4091 [00:39<00:03, 96.81it/s, loss=4.32, v_num=0, loss/va\u001b[A\n",
      "Epoch 16:  93%|▉| 3807/4091 [00:39<00:02, 97.23it/s, loss=4.32, v_num=0, loss/va\u001b[A\n",
      "Epoch 16:  94%|▉| 3834/4091 [00:39<00:02, 97.64it/s, loss=4.32, v_num=0, loss/va\u001b[A\n",
      "Epoch 16:  94%|▉| 3861/4091 [00:39<00:02, 98.05it/s, loss=4.32, v_num=0, loss/va\u001b[A\n",
      "Validating:  43%|████████████                | 174/404 [00:01<00:01, 212.63it/s]\u001b[A\n",
      "Epoch 16:  95%|▉| 3888/4091 [00:39<00:02, 98.45it/s, loss=4.32, v_num=0, loss/va\u001b[A\n",
      "Epoch 16:  96%|▉| 3915/4091 [00:39<00:01, 98.85it/s, loss=4.32, v_num=0, loss/va\u001b[A\n",
      "Epoch 16:  96%|▉| 3942/4091 [00:39<00:01, 99.25it/s, loss=4.32, v_num=0, loss/va\u001b[A\n",
      "Epoch 16:  97%|▉| 3969/4091 [00:39<00:01, 99.65it/s, loss=4.32, v_num=0, loss/va\u001b[A\n",
      "Epoch 16:  98%|▉| 3996/4091 [00:39<00:00, 100.03it/s, loss=4.32, v_num=0, loss/v\u001b[A\n",
      "Epoch 16:  98%|▉| 4023/4091 [00:40<00:00, 100.42it/s, loss=4.32, v_num=0, loss/v\u001b[A\n",
      "Epoch 16:  99%|▉| 4050/4091 [00:40<00:00, 100.80it/s, loss=4.32, v_num=0, loss/v\u001b[A\n",
      "Epoch 16: 100%|▉| 4077/4091 [00:40<00:00, 101.20it/s, loss=4.32, v_num=0, loss/v\u001b[A\n",
      "Epoch 16: 100%|█| 4091/4091 [00:40<00:00, 101.17it/s, loss=4.32, v_num=0, loss/v\u001b[A\n",
      "Epoch 17:  90%|▉| 3687/4091 [00:37<00:04, 98.45it/s, loss=4.39, v_num=0, loss/va\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                       | 0/404 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 17:  90%|▉| 3699/4091 [00:38<00:04, 97.22it/s, loss=4.39, v_num=0, loss/va\u001b[A\n",
      "Epoch 17:  91%|▉| 3726/4091 [00:38<00:03, 97.65it/s, loss=4.39, v_num=0, loss/va\u001b[A\n",
      "Epoch 17:  92%|▉| 3753/4091 [00:38<00:03, 98.07it/s, loss=4.39, v_num=0, loss/va\u001b[A\n",
      "Epoch 17:  92%|▉| 3780/4091 [00:38<00:03, 98.49it/s, loss=4.39, v_num=0, loss/va\u001b[A\n",
      "Epoch 17:  93%|▉| 3807/4091 [00:38<00:02, 98.90it/s, loss=4.39, v_num=0, loss/va\u001b[A\n",
      "Epoch 17:  94%|▉| 3834/4091 [00:38<00:02, 99.31it/s, loss=4.39, v_num=0, loss/va\u001b[A\n",
      "Validating:  37%|██████████▎                 | 148/404 [00:01<00:01, 197.25it/s]\u001b[A\n",
      "Epoch 17:  94%|▉| 3861/4091 [00:38<00:02, 99.72it/s, loss=4.39, v_num=0, loss/va\u001b[A\n",
      "Epoch 17:  95%|▉| 3888/4091 [00:38<00:02, 100.13it/s, loss=4.39, v_num=0, loss/v\u001b[A\n",
      "Epoch 17:  96%|▉| 3915/4091 [00:38<00:01, 100.54it/s, loss=4.39, v_num=0, loss/v\u001b[A\n",
      "Epoch 17:  96%|▉| 3942/4091 [00:39<00:01, 100.95it/s, loss=4.39, v_num=0, loss/v\u001b[A\n",
      "Epoch 17:  97%|▉| 3969/4091 [00:39<00:01, 101.35it/s, loss=4.39, v_num=0, loss/v\u001b[A\n",
      "Epoch 17:  98%|▉| 3996/4091 [00:39<00:00, 101.75it/s, loss=4.39, v_num=0, loss/v\u001b[A\n",
      "Epoch 17:  98%|▉| 4023/4091 [00:39<00:00, 102.15it/s, loss=4.39, v_num=0, loss/v\u001b[A\n",
      "Epoch 17:  99%|▉| 4050/4091 [00:39<00:00, 102.55it/s, loss=4.39, v_num=0, loss/v\u001b[A\n",
      "Epoch 17: 100%|▉| 4077/4091 [00:39<00:00, 102.95it/s, loss=4.39, v_num=0, loss/v\u001b[A\n",
      "Epoch 17: 100%|█| 4091/4091 [00:39<00:00, 102.90it/s, loss=4.39, v_num=0, loss/v\u001b[A\n",
      "Epoch 18:  90%|▉| 3687/4091 [00:37<00:04, 97.55it/s, loss=4.33, v_num=0, loss/va\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                       | 0/404 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 18:  90%|▉| 3699/4091 [00:38<00:04, 96.34it/s, loss=4.33, v_num=0, loss/va\u001b[A\n",
      "Epoch 18:  91%|▉| 3726/4091 [00:38<00:03, 96.79it/s, loss=4.33, v_num=0, loss/va\u001b[A\n",
      "Epoch 18:  92%|▉| 3753/4091 [00:38<00:03, 97.19it/s, loss=4.33, v_num=0, loss/va\u001b[A\n",
      "Epoch 18:  92%|▉| 3780/4091 [00:38<00:03, 97.60it/s, loss=4.33, v_num=0, loss/va\u001b[A\n",
      "Epoch 18:  93%|▉| 3807/4091 [00:38<00:02, 98.01it/s, loss=4.33, v_num=0, loss/va\u001b[A\n",
      "Validating:  30%|████████▍                   | 121/404 [00:01<00:01, 177.38it/s]\u001b[A\n",
      "Epoch 18:  94%|▉| 3834/4091 [00:38<00:02, 98.42it/s, loss=4.33, v_num=0, loss/va\u001b[A\n",
      "Epoch 18:  94%|▉| 3861/4091 [00:39<00:02, 98.83it/s, loss=4.33, v_num=0, loss/va\u001b[A\n",
      "Epoch 18:  95%|▉| 3888/4091 [00:39<00:02, 99.24it/s, loss=4.33, v_num=0, loss/va\u001b[A\n",
      "Epoch 18:  96%|▉| 3915/4091 [00:39<00:01, 99.65it/s, loss=4.33, v_num=0, loss/va\u001b[A\n",
      "Epoch 18:  96%|▉| 3942/4091 [00:39<00:01, 100.06it/s, loss=4.33, v_num=0, loss/v\u001b[A\n",
      "Epoch 18:  97%|▉| 3969/4091 [00:39<00:01, 100.46it/s, loss=4.33, v_num=0, loss/v\u001b[A\n",
      "Epoch 18:  98%|▉| 3996/4091 [00:39<00:00, 100.86it/s, loss=4.33, v_num=0, loss/v\u001b[A\n",
      "Epoch 18:  98%|▉| 4023/4091 [00:39<00:00, 101.26it/s, loss=4.33, v_num=0, loss/v\u001b[A\n",
      "Epoch 18:  99%|▉| 4050/4091 [00:39<00:00, 101.66it/s, loss=4.33, v_num=0, loss/v\u001b[A\n",
      "Epoch 18: 100%|▉| 4077/4091 [00:39<00:00, 102.05it/s, loss=4.33, v_num=0, loss/v\u001b[A\n",
      "Epoch 18: 100%|█| 4091/4091 [00:40<00:00, 102.03it/s, loss=4.33, v_num=0, loss/v\u001b[A\n",
      "Epoch 19:  90%|▉| 3687/4091 [00:37<00:04, 98.52it/s, loss=4.28, v_num=0, loss/va\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                       | 0/404 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 19:  90%|▉| 3699/4091 [00:38<00:04, 97.25it/s, loss=4.28, v_num=0, loss/va\u001b[A\n",
      "Epoch 19:  91%|▉| 3726/4091 [00:38<00:03, 97.70it/s, loss=4.28, v_num=0, loss/va\u001b[A\n",
      "Epoch 19:  92%|▉| 3753/4091 [00:38<00:03, 98.12it/s, loss=4.28, v_num=0, loss/va\u001b[A\n",
      "Epoch 19:  92%|▉| 3780/4091 [00:38<00:03, 98.54it/s, loss=4.28, v_num=0, loss/va\u001b[A\n",
      "Epoch 19:  93%|▉| 3807/4091 [00:38<00:02, 98.95it/s, loss=4.28, v_num=0, loss/va\u001b[A\n",
      "Epoch 19:  94%|▉| 3834/4091 [00:38<00:02, 99.36it/s, loss=4.28, v_num=0, loss/va\u001b[A\n",
      "Validating:  37%|██████████▎                 | 149/404 [00:01<00:01, 198.38it/s]\u001b[A\n",
      "Epoch 19:  94%|▉| 3861/4091 [00:38<00:02, 99.76it/s, loss=4.28, v_num=0, loss/va\u001b[A\n",
      "Epoch 19:  95%|▉| 3888/4091 [00:38<00:02, 100.17it/s, loss=4.28, v_num=0, loss/v\u001b[A\n",
      "Epoch 19:  96%|▉| 3915/4091 [00:38<00:01, 100.57it/s, loss=4.28, v_num=0, loss/v\u001b[A\n",
      "Epoch 19:  96%|▉| 3942/4091 [00:39<00:01, 100.97it/s, loss=4.28, v_num=0, loss/v\u001b[A\n",
      "Epoch 19:  97%|▉| 3969/4091 [00:39<00:01, 101.38it/s, loss=4.28, v_num=0, loss/v\u001b[A\n",
      "Epoch 19:  98%|▉| 3996/4091 [00:39<00:00, 101.78it/s, loss=4.28, v_num=0, loss/v\u001b[A\n",
      "Epoch 19:  98%|▉| 4023/4091 [00:39<00:00, 102.18it/s, loss=4.28, v_num=0, loss/v\u001b[A\n",
      "Epoch 19:  99%|▉| 4050/4091 [00:39<00:00, 102.57it/s, loss=4.28, v_num=0, loss/v\u001b[A\n",
      "Epoch 19: 100%|▉| 4077/4091 [00:39<00:00, 102.96it/s, loss=4.28, v_num=0, loss/v\u001b[A\n",
      "Epoch 19: 100%|█| 4091/4091 [00:39<00:00, 102.93it/s, loss=4.28, v_num=0, loss/v\u001b[A\n",
      "Epoch 19: 100%|█| 4091/4091 [00:39<00:00, 102.80it/s, loss=4.28, v_num=0, loss/v\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml/.pyenv/versions/3.9.7/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:469: LightningDeprecationWarning: DataModule.teardown has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.teardown.\n",
      "  rank_zero_deprecation(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing:  97%|██████████████████████████████ | 449/463 [00:02<00:00, 245.32it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'loss/test': 4.3150153160095215, 'perplexity/test': 76.4348373413086}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|███████████████████████████████| 463/463 [00:02<00:00, 182.15it/s]\n",
      "[{'loss/test': 4.3150153160095215, 'perplexity/test': 76.4348373413086}]\n"
     ]
    }
   ],
   "source": [
    "# Train LSTM\n",
    "lstm_data_module = TextDateModule(train, valid, test)\n",
    "lstm_model = TextLSTMModule(vocab_size)\n",
    "\n",
    "tb_logger = pl_loggers.TensorBoardLogger(\"./lightning_logs/\", name=\"network_2\")\n",
    "trainer = pl.Trainer(logger=tb_logger, gradient_clip_val=0.5, max_epochs=20, gpus=1)\n",
    "trainer.fit(lstm_model, data_module)\n",
    "\n",
    "result = trainer.test(lstm_model, data_module)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7442223-3d62-4514-b1ff-d840601d87bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show results\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./lightning_logs/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
